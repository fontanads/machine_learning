{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from collections import Counter # collections library; counter: dict subclass for counting hashable objects\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import my_sentence_tokenizer, get_all_tokens, encode_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Corpus Data to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'> 37360\n"
     ]
    }
   ],
   "source": [
    "hamlet_corpus = gutenberg.words('shakespeare-hamlet.txt')\n",
    "print(type(hamlet_corpus),len(hamlet_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 166764\n"
     ]
    }
   ],
   "source": [
    "corpus_str = ' '.join(hamlet_corpus)\n",
    "print(type(corpus_str),len(corpus_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_str = re.sub(r'[,!?;-]+', '.', corpus_str) # clean punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_start = '<s>'\n",
    "tag_end = '</s>'\n",
    "tag_oov = '<unk>'\n",
    "tag_pad = '<pad>'\n",
    "\n",
    "tags = [tag_start, tag_end, tag_oov, tag_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = my_sentence_tokenizer(corpus_str,tag_start,tag_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = get_all_tokens(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning:  47309 tokens, first 100  ['<s>', 'the', 'tragedie', 'of', 'hamlet', 'by', 'william', 'shakespeare', 'actus', 'primus', '.', '</s>', '<s>', 'scoena', 'prima', '.', '</s>', '<s>', 'enter', 'barnardo', 'and', 'francisco', 'two', 'centinels', '.', '</s>', '<s>', 'barnardo', '.', '</s>', '<s>', 'who', 's', 'there', '.', '</s>', '<s>', 'fran', '.', '</s>', '<s>', 'nay', 'answer', 'me', 'stand', 'vnfold', 'your', 'selfe', 'bar', '.', '</s>', '<s>', 'long', 'liue', 'the', 'king', 'fran', '.', '</s>', '<s>', 'barnardo', '.', '</s>', '<s>', 'bar', '.', '</s>', '<s>', 'he', 'fran', '.', '</s>', '<s>', 'you', 'come', 'most', 'carefully', 'vpon', 'your', 'houre', 'bar', '.', '</s>', '<s>', 'tis', 'now', 'strook', 'twelue', '.', '</s>', '<s>', 'get', 'thee', 'to', 'bed', 'francisco', 'fran', '.', '</s>', '<s>']\n"
     ]
    }
   ],
   "source": [
    "n_print = 100\n",
    "print(f'After cleaning:  {len(tokens)} tokens, first {n_print}  {tokens[:n_print]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 5672), ('the', 993), ('and', 863), ('to', 685), ('of', 610), ('i', 574), ('you', 527), ('a', 511), ('my', 502), ('it', 419)]\n",
      "count :  4699\n"
     ]
    }
   ],
   "source": [
    "# create vocab including word count using collections.Counter\n",
    "word_count_vocab = dict()\n",
    "word_count_vocab = Counter(tokens)\n",
    "\n",
    "word_count_vocab.pop(tag_start)\n",
    "word_count_vocab.pop(tag_end)\n",
    "\n",
    "print(word_count_vocab.most_common(10))\n",
    "print('count : ',len(word_count_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '<s>'),\n",
       " (1, '</s>'),\n",
       " (2, '<unk>'),\n",
       " (3, '<pad>'),\n",
       " (4, '.'),\n",
       " (5, 'a'),\n",
       " (6, 'abhominably'),\n",
       " (7, 'abhorred'),\n",
       " (8, 'abilitie'),\n",
       " (9, 'aboord')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = list(enumerate(sorted(set(word_count_vocab.keys())),start=4))\n",
    "\n",
    "for i, tag in enumerate(tags):\n",
    "    vocabulary.insert(i,(i,tag))\n",
    "vocabulary[:10] # sorted vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '<s>'),\n",
       " (1, '</s>'),\n",
       " (2, '<unk>'),\n",
       " (3, '<pad>'),\n",
       " (4, '.'),\n",
       " (5, 'a'),\n",
       " (6, 'abhominably'),\n",
       " (7, 'abhorred'),\n",
       " (8, 'abilitie'),\n",
       " (9, 'aboord')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word = dict(vocabulary)\n",
    "list(idx2word.items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 0),\n",
       " ('</s>', 1),\n",
       " ('<unk>', 2),\n",
       " ('<pad>', 3),\n",
       " ('.', 4),\n",
       " ('a', 5),\n",
       " ('abhominably', 6),\n",
       " ('abhorred', 7),\n",
       " ('abilitie', 8),\n",
       " ('aboord', 9)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = dict({k:v for v, k in idx2word.items()})\n",
    "list(word2idx.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded_corpus = [encode_sentence(s,word2idx, max_len_sentence=30,\n",
    "                               tag_oov=tag_oov, tag_pad=tag_pad) for s in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 2802, 1484, 4, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5672"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(coded_corpus[202])\n",
    "len(coded_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = len(coded_corpus)           \n",
    "T = len(coded_corpus[0]) # max_len_sentence + 2\n",
    "V = len(word2idx)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll see how to use the ``Embedding`` layer of Torch. <br>\n",
    "It converts categorical data with $V$ classes to dense vectors with $N_d$ dimensions. <br>\n",
    "Suppose $c\\in{F_2^V}$ is a one-hot encoded vector. <br>\n",
    "An embedding is a mapping $e:F_2^V\\to R^{N_d}$ (sparse vector, one-hot encoded, to dense real vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nd = 2                  # Number of Dimensions of the Dense embedding\n",
    "e = nn.Embedding(V,Nd)  # (vocab_size, num_of_dimensions_of_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first convert the coded sentences to Torch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded_sentences = torch.LongTensor(coded_corpus).reshape(-1,T).T\n",
    "print(f' T x S : {coded_sentences.shape} (max. sentence size + 2 x num. of sentences)')\n",
    "print(f' Tensors of type {coded_sentences.dtype}')\n",
    "print(' All encoded sentences as tensors (each column is a sentence):')\n",
    "print(coded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select, for example, the first sentence, as the varible $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = coded_sentences[:,0]\n",
    "print(c.shape,c,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the sentence from sequences of one-hot-encoded words to its embedding vector.<br>\n",
    "When printing the corresponding sequence, we see that:\n",
    "- each index (one-hot-encoded word) is converted into a real row-vector of $N_d$ dimensions\n",
    "- the initialized embedding vectors are just random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_seq = e(c)\n",
    "print(e_seq.shape,e_seq[:10,:],'... and more words (truncated in the 10-th word).',sep='\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a word to check its embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word    = 'queen'\n",
    "\n",
    "idx     = word2idx[word] # uses dictionary to map word to index\n",
    "emb_vec = e(torch.LongTensor([idx]))  # uses torch embedding to map index to dense Nd-vector\n",
    "\n",
    "print(f' Word \"{word}\" corresponds to index {idx}')\n",
    "print(f' Index {idx} maps to embedding vector \"{emb_vec.detach().numpy().reshape(-1).tolist()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = e.weight.data\n",
    "W1.shape, W1.dtype, W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
