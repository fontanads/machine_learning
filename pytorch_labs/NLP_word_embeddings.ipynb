{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NLP Word Embeddings with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/50747947/embedding-in-pytorch\n",
    "# https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "#!pip install --user \"git+https://github.com/javadba/mpld3@display_fix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import re\n",
    "from collections import Counter # collections library; counter: dict subclass for counting hashable objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_labs.utils import my_sentence_tokenizer, get_all_tokens, encode_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_start = '<s>'\n",
    "tag_end = '</s>'\n",
    "tag_oov = '<unk>'\n",
    "tag_pad = '<pad>'\n",
    "\n",
    "tags = dict({'tag_start':tag_start, 'tag_end':tag_end,'tag_oov':tag_oov, 'tag_pad':tag_pad})\n",
    "\n",
    "max_len_sentence = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'> 260819\n",
      "<class 'str'> 1259862\n",
      "After cleaning:  330684 tokens, first 100  ['<s>', 'moby', 'dick', 'by', 'herman', 'melville', 'etymology', '.', '</s>', '<s>', 'supplied', 'by', 'a', 'late', 'consumptive', 'usher', 'to', 'a', 'grammar', 'school', 'the', 'pale', 'usher', '.', '</s>', '<s>', 'threadbare', 'in', 'coat', '.', '</s>', '<s>', 'heart', '.', '</s>', '<s>', 'body', '.', '</s>', '<s>', 'and', 'brain', '.', '</s>', '<s>', 'i', 'see', 'him', 'now', '.', '</s>', '<s>', 'he', 'was', 'ever', 'dusting', 'his', 'old', 'lexicons', 'and', 'grammars', '.', '</s>', '<s>', 'with', 'a', 'queer', 'handkerchief', '.', '</s>', '<s>', 'mockingly', 'embellished', 'with', 'all', 'the', 'gay', 'flags', 'of', 'all', 'the', 'known', 'nations', 'of', 'the', 'world', '.', '</s>', '<s>', 'he', 'loved', 'to', 'dust', 'his', 'old', 'grammars', '.', '</s>', '<s>', 'it']\n",
      "[('.', 37440), ('the', 14431), ('of', 6609), ('and', 6430), ('a', 4736), ('to', 4625), ('in', 4172), ('that', 3085), ('his', 2530), ('it', 2522)]\n",
      "count :  16948\n",
      "[(0, '<s>'), (1, '</s>'), (2, '<unk>'), (3, '<pad>'), (4, '.'), (5, 'a'), (6, 'aback'), (7, 'abaft'), (8, 'abandon'), (9, 'abandoned')]\n",
      "[0, 8528, 15983, 5726, 4, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "37407\n"
     ]
    }
   ],
   "source": [
    "corpus = gutenberg.words('melville-moby_dick.txt') # 'melville-moby_dick.txt' 'shakespeare-hamlet.txt'\n",
    "print(type(corpus),len(corpus))\n",
    "corpus_str = ' '.join(corpus)\n",
    "\n",
    "#with open(\"./data/wiki_sample_corpusdataorg.txt\", \"rb\") as f:\n",
    "#    txt = f.readlines()\n",
    "#corpus_str = ''.join([s.decode('utf-8') for s in txt])\n",
    "\n",
    "\n",
    "\n",
    "print(type(corpus_str),len(corpus_str))\n",
    "corpus_str = re.sub(r'[,!?;-]+', '.', corpus_str) # clean punctuation\n",
    "\n",
    "doc = my_sentence_tokenizer(corpus_str,tag_start,tag_end)\n",
    "tokens = get_all_tokens(doc)\n",
    "\n",
    "n_print = 100\n",
    "print(f'After cleaning:  {len(tokens)} tokens, first {n_print}  {tokens[:n_print]}')\n",
    "\n",
    "# create vocab including word count using collections.Counter\n",
    "word_count_vocab = dict()\n",
    "word_count_vocab = Counter(tokens)\n",
    "\n",
    "word_count_vocab.pop(tag_start)\n",
    "word_count_vocab.pop(tag_end)\n",
    "\n",
    "print(word_count_vocab.most_common(10))\n",
    "print('count : ',len(word_count_vocab))\n",
    "\n",
    "vocabulary = list(enumerate(sorted(set(word_count_vocab.keys())),start=4))\n",
    "\n",
    "for i, tag in enumerate(list(tags.values())):\n",
    "    vocabulary.insert(i,(i,tag))\n",
    "print(vocabulary[:10]) # sorted vocabulary\n",
    "\n",
    "idx2word = dict(vocabulary)\n",
    "list(idx2word.items())[0:10]\n",
    "\n",
    "word2idx = dict({k:v for v, k in idx2word.items()})\n",
    "list(word2idx.items())[:10]\n",
    "\n",
    "coded_corpus = [encode_sentence(s,word2idx, max_len_sentence=max_len_sentence,\n",
    "                               tag_oov=tag_oov, tag_pad=tag_pad) for s in doc]\n",
    "\n",
    "print(coded_corpus[202])\n",
    "print(len(coded_corpus))\n",
    "\n",
    "S = len(coded_corpus)           \n",
    "T = len(coded_corpus[0]) # max_len_sentence + 2\n",
    "V = len(word2idx)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37407, 15, 16952)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S, T, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37407, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coded_corpus_np = np.array(coded_corpus)\n",
    "coded_corpus_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(coded_sentence, context_size,word2idx, tags, T):\n",
    "    \n",
    "    # end_position = np.where(coded_sentence==word2idx[tags['tag_end']])[0].item()\n",
    "    # apesar de quebrar a frase na hora certa, gera um problema de batches de tamanhos diferentes\n",
    "    \n",
    "    end_position = T\n",
    "    \n",
    "    target_context = []\n",
    "    for pos in range(0,end_position):\n",
    "        middle_word   = coded_sentence[pos]\n",
    "\n",
    "        left_start = max(pos-context_size,0)\n",
    "        right_end  = min(pos+1+context_size,end_position)\n",
    "\n",
    "        if pos - left_start < context_size:                # first words position\n",
    "            right_end += context_size-(pos-left_start)     # --> increse right_context size\n",
    "        elif right_end-(pos+1) < context_size:             # last words position\n",
    "            left_start -= context_size-(right_end-(pos+1)) # --> increase left_context size\n",
    "\n",
    "        left_context  = coded_sentence[left_start:pos]\n",
    "        right_context = coded_sentence[pos+1:right_end]\n",
    "        \n",
    "        \n",
    "        context       = left_context + right_context # list concatenation\n",
    "\n",
    "        target_context.append((middle_word,context))\n",
    "    return target_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(coded_corpus, batch_size, half_context_size, S, T, V, word2idx, tags):\n",
    "    i = 0\n",
    "    while True:\n",
    "        sentences = coded_corpus[i:i+batch_size]\n",
    "        X = []\n",
    "        Y = []\n",
    "        for s in sentences:\n",
    "            for y, x in get_context(s, half_context_size, word2idx, tags, T):\n",
    "                X.append(x)\n",
    "                Y.append(y)\n",
    "        yield (np.array(X), np.array(Y).reshape(-1,1))\n",
    "        \n",
    "        i += batch_size\n",
    "        if i >= S-batch_size:\n",
    "            print('i is being set to 0')\n",
    "            i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_vectors(context_batches, middle_word_batches):\n",
    "    X_train = np.zeros(shape=(batch_size*T,V))\n",
    "    #Y_train = np.zeros(shape=(batch_size*T,V))\n",
    "    Y_train = np.zeros(shape=(batch_size*T))\n",
    "    \n",
    "    for context_id in range(context_batches.shape[0]):\n",
    "        context     = context_batches[context_id]\n",
    "        middle_word = middle_word_batches[context_id].item()\n",
    "        for cw in  context:\n",
    "            weight = 1 if word_count_vocab[idx2word[cw]] else 0\n",
    "            X_train[context_id, cw] += weight/(2*half_context_size)\n",
    "        \n",
    "        # Y_train[context_id, middle_word] = 1\n",
    "        Y_train[context_id] = middle_word\n",
    "    return (torch.FloatTensor(X_train), torch.LongTensor(Y_train))\n",
    "# X_train[np.where(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "half_context_size = 2\n",
    "batch_generator = get_batches(coded_corpus=coded_corpus, \n",
    "                              batch_size=batch_size, half_context_size=half_context_size, \n",
    "                              S=S, T=T, V=V, word2idx=word2idx, tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 4), (30, 1), 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y  = next(batch_generator)\n",
    "X.shape, Y.shape, (batch_size)*T\n",
    "#print(np.concatenate((X, Y),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Embeddings with Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag-of-Words (CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "context vs target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints about PyTorch input layer format</b></font>\n",
    "</summary>\n",
    "\n",
    "[from here](https://discuss.pytorch.org/t/confused-about-tensor-dimensions-and-batches/4761/2)\n",
    "\n",
    "    \n",
    "> The input to a linear layer should be a tensor of size [batch_size, input_size] where input_size is the same size as the first layer in your network (so in your case itâ€™s num_letters).  \n",
    "    The problem appears in the line:  \n",
    "    `tensor = torch.zeros(len(name), 1, num_letters)`  \n",
    "    which should actually just be:  \n",
    "    `tensor = torch.zeros(len(name), num_letters)`\n",
    "\n",
    "> As an easy example:  \n",
    "> ```python\n",
    "        input_size = 8\n",
    "        output_size = 14\n",
    "        batch_size = 64\n",
    "        net = nn.Linear(input_size, output_size)  \n",
    "        input = Variable(torch.FloatTensor(batch_size, input_size))  \n",
    "        output = net(input)  \n",
    "        print(\"Output size:\", output.size())\n",
    "    \n",
    "> ```CPP\n",
    "    Output size: (64, 14)\n",
    "    \n",
    "\n",
    "> Hope this helps,  \n",
    "  Jordan\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language_Model_w2v(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, num_of_dimensions_of_embedding):\n",
    "        super(Language_Model_w2v, self).__init__()\n",
    "        self.V  = vocab_size\n",
    "        self.N  = num_of_dimensions_of_embedding \n",
    "        \n",
    "        self.W1  = nn.Linear(self.V, self.N)\n",
    "        self.H1  = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.Winv = nn.Linear(self.N, self.V)\n",
    "        self.LogSoftMax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        # self.layers = nn.Sequential(*[self.e, self.W1, self.W2,self.LogSoftMax])\n",
    "        \n",
    "    def forward(self,x):              \n",
    "        x = self.H1(self.W1(x))\n",
    "        x = self.LogSoftMax(self.Winv(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 2\n",
    "batch_size = 200\n",
    "max_batch_iters = np.floor(S/batch_size)\n",
    "\n",
    "Nd = 100\n",
    "half_context_size = 4\n",
    "\n",
    "batch_generator = get_batches(coded_corpus=coded_corpus, \n",
    "                              batch_size=batch_size, half_context_size=half_context_size, \n",
    "                              S=S, T=T, V=V, word2idx=word2idx, tags=tags)\n",
    "\n",
    "print_iters = 10\n",
    "\n",
    "losses    = []\n",
    "criterion = nn.NLLLoss()\n",
    "model     = Language_Model_w2v(vocab_size=V, num_of_dimensions_of_embedding=Nd)\n",
    "optimizer = optim.Adam(model.parameters(), lr=7e-4) # optim.SGD(model.parameters(),lr=1e-2) #  #   # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language_Model_w2v(\n",
       "  (W1): Linear(in_features=16952, out_features=100, bias=True)\n",
       "  (H1): ReLU(inplace=True)\n",
       "  (Winv): Linear(in_features=100, out_features=16952, bias=True)\n",
       "  (LogSoftMax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_batch_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 sentence 200/37407 loss: 9.76057\n",
      "epoch 0 sentence 2200/37407 loss: 9.73403\n",
      "epoch 0 sentence 4200/37407 loss: 9.70723\n",
      "epoch 0 sentence 6200/37407 loss: 9.66506\n",
      "epoch 0 sentence 8200/37407 loss: 9.60799\n",
      "epoch 0 sentence 10200/37407 loss: 9.53666\n",
      "epoch 0 sentence 12200/37407 loss: 9.44488\n",
      "epoch 0 sentence 14200/37407 loss: 9.33934\n",
      "epoch 0 sentence 16200/37407 loss: 9.19838\n",
      "epoch 0 sentence 18200/37407 loss: 9.02305\n",
      "epoch 0 sentence 20200/37407 loss: 8.83608\n",
      "epoch 0 sentence 22200/37407 loss: 8.63199\n",
      "epoch 0 sentence 24200/37407 loss: 8.41055\n",
      "epoch 0 sentence 26200/37407 loss: 8.13377\n",
      "epoch 0 sentence 28200/37407 loss: 7.83277\n",
      "epoch 0 sentence 30200/37407 loss: 7.58087\n",
      "epoch 0 sentence 32200/37407 loss: 7.28294\n",
      "epoch 0 sentence 34200/37407 loss: 6.98696\n",
      "epoch 0 sentence 36200/37407 loss: 6.65421\n",
      "i is being set to 0\n",
      "epoch 1 sentence 200/37407 loss: 6.55069\n",
      "epoch 1 sentence 2200/37407 loss: 6.20869\n",
      "epoch 1 sentence 4200/37407 loss: 5.96030\n",
      "epoch 1 sentence 6200/37407 loss: 5.64348\n",
      "epoch 1 sentence 8200/37407 loss: 5.55948\n",
      "epoch 1 sentence 10200/37407 loss: 5.34794\n",
      "epoch 1 sentence 12200/37407 loss: 4.97348\n",
      "epoch 1 sentence 14200/37407 loss: 5.21226\n",
      "epoch 1 sentence 16200/37407 loss: 4.87685\n",
      "epoch 1 sentence 18200/37407 loss: 4.94614\n",
      "epoch 1 sentence 20200/37407 loss: 4.74433\n",
      "epoch 1 sentence 22200/37407 loss: 4.60239\n",
      "epoch 1 sentence 24200/37407 loss: 4.53283\n",
      "epoch 1 sentence 26200/37407 loss: 4.18314\n",
      "epoch 1 sentence 28200/37407 loss: 4.09608\n",
      "epoch 1 sentence 30200/37407 loss: 3.88329\n",
      "epoch 1 sentence 32200/37407 loss: 4.04804\n",
      "epoch 1 sentence 34200/37407 loss: 3.64940\n",
      "epoch 1 sentence 36200/37407 loss: 3.53589\n"
     ]
    }
   ],
   "source": [
    "batch_losses = []\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    cnt = 0\n",
    "    \n",
    "    # coded_sentences = coded_sentences[:,np.random.permutation(S)]\n",
    "    \n",
    "    for X, Y in batch_generator:\n",
    "    \n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words into integer indices and wrap them in tensors)\n",
    "        X_train, Y_train = get_train_vectors(context_batches=X, middle_word_batches = Y)\n",
    "        \n",
    "        # Step 2. Recall that torch *accumulates* gradients. \n",
    "        # Before passing in a new instance, you need to zero out the gradients from the oldinstance\n",
    "        model.zero_grad()\n",
    "            \n",
    "        # Step 3. Run the forward pass, getting log probabilities over next words\n",
    "        log_probs = model(X_train)  \n",
    "            \n",
    "        # Step 4. Compute your loss function. \n",
    "        # (Again, Torch wants the target word wrapped in a tensor)\n",
    "        loss = criterion(log_probs, Y_train.T)\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        # total_loss += loss.item()\n",
    "        \n",
    "        batch_losses.append(loss)\n",
    "        \n",
    "        \n",
    "        if cnt%print_iters==1:\n",
    "            print(f'epoch {epoch} sentence {cnt*batch_size}/{S} loss: {loss.item():.5f}')\n",
    "            \n",
    "        cnt+=1\n",
    "            \n",
    "        if cnt>=max_batch_iters:\n",
    "            break\n",
    "    \n",
    "    #time.sleep(1.5)\n",
    "    #clear_output()\n",
    "#print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3000, 16952])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for group in model.parameters():\n",
    "    print(group.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_losses_np = np.array([loss.detach() for loss in batch_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.plot(batch_losses_np)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1.weight torch.Size([100, 16952])\n",
      "W1.bias torch.Size([100])\n",
      "Winv.weight torch.Size([16952, 100])\n",
      "Winv.bias torch.Size([16952])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape) # param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16952, 100]),\n",
       " tensor([[ 0.1294,  0.0987, -0.0093,  ..., -0.0124, -0.0029,  0.0127],\n",
       "         [ 0.0820,  0.1265, -0.0016,  ...,  0.0171,  0.0218, -0.0268],\n",
       "         [-0.1638, -0.1563,  0.0012,  ..., -0.0271, -0.0374, -0.0172],\n",
       "         ...,\n",
       "         [-0.0497, -0.0550,  0.0391,  ..., -0.0505, -0.0113, -0.0265],\n",
       "         [-0.0988, -0.1464, -0.0125,  ..., -0.0295,  0.0454, -0.0154],\n",
       "         [-0.1210, -0.1383,  0.0444,  ..., -0.0087,  0.0376,  0.0473]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding = 1/2*(model.Winv.weight.data + model.W1.weight.data.T)\n",
    "Embedding.shape, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_analogy(pos_neg_1=('king','man'),pos_neg_2=('queen','woman'), n_closest = 4, word2idx=None, idx2word=None):\n",
    "    king_w,    man_w = pos_neg_1\n",
    "    queen_w, woman_w = pos_neg_2\n",
    "    \n",
    "    for w in (king_w,man_w,woman_w):\n",
    "        if w not in word2idx:\n",
    "            raise Exception(f'sorry, word \"{w}\" not in dictionary.')\n",
    "    \n",
    "    print(f'Expected: {king_w} - {man_w} = {queen_w} - {woman_w}')\n",
    "    \n",
    "    king   = word2idx[king_w]\n",
    "    man    = word2idx[man_w]\n",
    "    woman  = word2idx[woman_w]\n",
    "    \n",
    "    vec = (Embedding[king] - Embedding[man] + Embedding[woman]).view(1,-1) # Embedding[queen]\n",
    "    distances = pairwise_distances(vec.reshape(1, -1), Embedding, metric='cosine').reshape(V)\n",
    "    \n",
    "    idx = distances.argsort()[:n_closest+3] \n",
    "    idx = [x for x in idx if x not in set([man,king,woman])]\n",
    "    queen_estimated = idx2word[idx[0]]\n",
    "    \n",
    "    print(f'Got:      {king_w} - {man_w} = {queen_estimated} - {woman_w}')\n",
    "    \n",
    "    print(f'Closest {len(idx)} words:')\n",
    "    for i in idx:\n",
    "        print(f'{idx2word[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: king - man = queen - woman\n",
      "Got:      king - man = reigneth - woman\n",
      "Closest 7 words:\n",
      "reigneth\n",
      "establishing\n",
      "arguments\n",
      "transit\n",
      "frosted\n",
      "speculative\n",
      "epicurean\n"
     ]
    }
   ],
   "source": [
    "w1 = 'king'\n",
    "w2 = 'man'\n",
    "w3 = 'queen'\n",
    "w4 = 'woman'\n",
    "\n",
    "word_analogy(pos_neg_1=(w1,w2),pos_neg_2=(w3,w4), n_closest = 4, word2idx=word2idx, idx2word=idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: man - woman = he - she\n",
      "Got:      man - woman = it - she\n",
      "Closest 6 words:\n",
      "it\n",
      "and\n",
      "in\n",
      "a\n",
      "<s>\n",
      "then\n"
     ]
    }
   ],
   "source": [
    "w1 = 'man'\n",
    "w2 = 'woman'\n",
    "w3 = 'he'\n",
    "w4 = 'she'\n",
    "\n",
    "word_analogy(pos_neg_1=(w1,w2),pos_neg_2=(w3,w4), n_closest = 4, word2idx=word2idx, idx2word=idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: man - woman = husband - wife\n",
      "Got:      man - woman = it - wife\n",
      "Closest 6 words:\n",
      "it\n",
      "and\n",
      "for\n",
      "the\n",
      "of\n",
      "so\n"
     ]
    }
   ],
   "source": [
    "w1 = 'man'\n",
    "w2 = 'woman'\n",
    "w3 = 'husband'\n",
    "w4 = 'wife'\n",
    "\n",
    "word_analogy(pos_neg_1=(w1,w2),pos_neg_2=(w3,w4), n_closest = 4, word2idx=word2idx, idx2word=idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: boy - man = girl - woman\n",
      "Got:      boy - man = underlings - woman\n",
      "Closest 7 words:\n",
      "underlings\n",
      "intricacy\n",
      "founder\n",
      "dismantled\n",
      "counsellors\n",
      "characterizing\n",
      "slogan\n"
     ]
    }
   ],
   "source": [
    "w1 = 'boy'\n",
    "w2 = 'man'\n",
    "w3 = 'girl'\n",
    "w4 = 'woman'\n",
    "\n",
    "word_analogy(pos_neg_1=(w1,w2),pos_neg_2=(w3,w4), n_closest = 4, word2idx=word2idx, idx2word=idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: i - me = he - his\n",
      "Got:      i - me = and - his\n",
      "Closest 5 words:\n",
      "and\n",
      "a\n",
      "that\n",
      "but\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "w1 = 'i'\n",
    "w2 = 'me'\n",
    "w3 = 'he'\n",
    "w4 = 'his'\n",
    "\n",
    "word_analogy(pos_neg_1=(w1,w2),pos_neg_2=(w3,w4), n_closest = 4, word2idx=word2idx, idx2word=idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: prince - king = princess - queen\n",
      "Got:      prince - king = scornfully - queen\n",
      "Closest 6 words:\n",
      "scornfully\n",
      "exasperate\n",
      "timberheads\n",
      "rechurned\n",
      "assistants\n",
      "playfully\n"
     ]
    }
   ],
   "source": [
    "w1 = 'prince'\n",
    "w2 = 'king'\n",
    "w3 = 'princess'\n",
    "w4 = 'queen'\n",
    "\n",
    "word_analogy(pos_neg_1=(w1,w2),pos_neg_2=(w3,w4), n_closest = 4, word2idx=word2idx, idx2word=idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_count_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Visualization of Word-Analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(Embedding)\n",
    "Embedding_2D = pca.transform(Embedding)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(11,11))\n",
    "\n",
    "Nplot = 100\n",
    "\n",
    "most_common_words = [word2idx[x[0]] for x in word_count_vocab.most_common(Nplot)]\n",
    "\n",
    "plt.scatter(x=Embedding_2D[most_common_words,0], y=Embedding_2D[most_common_words,1])\n",
    "\n",
    "for i in most_common_words:\n",
    "    plt.annotate(idx2word[i], xy=(Embedding_2D[i,0],Embedding_2D[i,1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure()\n",
    "\n",
    "# output to static HTML file\n",
    "output_file(\"embeeded_word_vectors_pca.html\")\n",
    "\n",
    "Nplot = 2500\n",
    "\n",
    "most_common_words = [word2idx[x[0]] for x in word_count_vocab.most_common(Nplot)]\n",
    "\n",
    "p.scatter(x=Embedding_2D[most_common_words,0], y=Embedding_2D[most_common_words,1])\n",
    "\n",
    "for i in most_common_words:\n",
    "    my_text = Label(text=idx2word[i], x=Embedding_2D[i,0],y=Embedding_2D[i,1])\n",
    "    p.add_layout(my_text)\n",
    "    \n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
