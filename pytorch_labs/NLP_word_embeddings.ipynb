{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NLP Word Embeddings with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/50747947/embedding-in-pytorch\n",
    "# https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wikipedia\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "#!pip install --user \"git+https://github.com/javadba/mpld3@display_fix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-Scraper collects corpus from Wikipedia in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Wikipedia_Crawler` class uses the `wikipedia` module to load a _corpus_ in real time.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_labs.my_nlp_classes import Wikipedia_Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to set the desired language of the searches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang('pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will search specific wikis from the input query and downloads its content.\n",
    "- `query_list` is the list of query text to look for in Wikipedia\n",
    "- `max_results` is the maximum number of pages to load per query expression in the `query_list`\n",
    "- `max_v` will be used later to limit the vocabulary size of our custom dictionary\n",
    "- `skip_top` is the number of most frequent words (descending order) to be discard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list  = ['Rainha','Rei','Mulher','Homem','Brasil','Japão','Família','Tempo','Calendário'] #  \n",
    "max_results = 3\n",
    "max_V       = 3000\n",
    "skip_top    = 0\n",
    "max_len_sentence = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell, we instantiate the crawler with its basic query parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_crawler = Wikipedia_Crawler(query_list=query_list,max_results_per_query=max_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the desired wiki pages, we call for `query_wiki`. <br>\n",
    "The methods `get_wiki_sentences` downloads and tokenizes the sentences of the pages. <br> \n",
    "Then, `get_all_tokens` lists all unique tokens (words) in the data. Tokenization is performed in the process. <br>\n",
    "Finally, `count_vocabulary` counts the absolute frequency of each token. Tokenization is performed in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_crawler.query_wiki()\n",
    "wiki_crawler.get_wiki_sentences()\n",
    "wiki_crawler.get_all_tokens()\n",
    "wiki_crawler.count_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the tokens may be prohibitive. Thus, it is necessary to limit the vocabulary. <br>\n",
    "- `generate_vocabulary` will create `word2idx` and `idx2word` dictionaries \n",
    "- - dictionaries will be limited with `max_V` words ($+ 3$ tags)\n",
    "- - note that `skip_top` most frequent words will be discarded\n",
    "- `encode_all_sentence` will encode sentences of words into sequences (lists) of corresponding indexes\n",
    "- - encoded sentences will have additional `\"<START>\"` and `\"<END>\"` tokens\n",
    "- - words out of vocabulary will be coded with index of `\"<OOV>\"` tag\n",
    "- - encoded senteces will be truncated with `max_len_sentence` actual words ($+ 2$ start/end tags)\n",
    "- - encoded senteces padded by default, unless `pad_sentences` is set to `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_crawler.generate_vocabulary(max_len_vocabulary=max_V, skip_top_words=skip_top)\n",
    "wiki_crawler.encode_all_sentence(max_len_sentence=max_len_sentence, pad_sentences=True) # pad_sentences is True by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check where did the corpus came from and other results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Corpus derived from the following wiki pages: \n",
      " ---- ['Rainha', 'A Rainha', 'Salve-rainha', 'Rei', 'O Rei Leão', 'Rei (xadrez)', 'Mulher', 'Mulher-Gato', 'Mulher-Maravilha', 'Homem', 'Homem-Aranha', 'O Homem Elefante', 'Brasil', 'Município (Brasil)', 'Presidente do Brasil', 'Japão', 'História do Japão', 'Culinária do Japão', 'Família', 'Família Jackson', 'Família Gracie', 'Tempo', 'O Tempo Não Para', 'Tempo verbal', 'Calendário', 'Calendário gregoriano', 'Calendário chinês']\n",
      " Number of sentences: ------ 4079\n",
      " Max. words in sentence: --- 100\n",
      " Vocabulary Size: ---------- 3003\n"
     ]
    }
   ],
   "source": [
    "S = len(wiki_crawler.sentences)           \n",
    "T = len(wiki_crawler.coded_sentences[0]) # max_len_sentence + 2\n",
    "V = len(wiki_crawler.word2idx)           # max_V + 2\n",
    "\n",
    "print(f' Corpus derived from the following wiki pages: \\n ---- {wiki_crawler.titles_list}')\n",
    "print(f' Number of sentences: ------ {S}')\n",
    "print(f' Max. words in sentence: --- {T-2}')\n",
    "print(f' Vocabulary Size: ---------- {V}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we can check the generated sentences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Real Text sentence: \n",
      "    entre os reis davi de judá e israel, não é mencionado uma única rainha reinante; apesar de atália, embora a bíblia se refira negativamente como uma usurpadora.\n",
      "\n",
      " Encoded Sentence: \n",
      "    [1, 35, 15, 1577, 0, 3, 0, 6, 0, 27, 18, 0, 16, 567, 120, 611, 228, 3, 0, 123, 4, 949, 12, 2247, 0, 19, 16, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      " Decoded Sentence: \n",
      "    <START> entre os reis de e não é uma única rainha reinante apesar de embora a bíblia se refira como uma <END>\n"
     ]
    }
   ],
   "source": [
    "num_sentence = 5\n",
    "\n",
    "real_sentence    = wiki_crawler.sentences[num_sentence]\n",
    "encoded_sentece  = wiki_crawler.coded_sentences[num_sentence]\n",
    "decoded_sentence = wiki_crawler.decode_one_sentence(encoded_sentece)\n",
    "\n",
    "print(f' Real Text sentence: \\n    {real_sentence}', end=2*'\\n')\n",
    "print(f' Encoded Sentence: \\n    {encoded_sentece}', end=2*'\\n')\n",
    "print(f' Decoded Sentence: \\n    '+' '.join(decoded_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can see how to use the dictionary directly to convert `wor2idx` or `idx2word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Word \"mulher\" corresponds to index 37\n",
      " Index 9 corresponds to word \"que\"\n"
     ]
    }
   ],
   "source": [
    "word = 'mulher'\n",
    "idx = 9\n",
    "print(f' Word \"{word}\" corresponds to index {wiki_crawler.word2idx[word]}')\n",
    "print(f' Index {idx} corresponds to word \"{wiki_crawler.idx2word[idx]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll see how to use the ``Embedding`` layer of Torch. <br>\n",
    "It converts categorical data with $V$ classes to dense vectors with $N_d$ dimensions. <br>\n",
    "Suppose $c\\in{F_2^V}$ is a one-hot encoded vector. <br>\n",
    "An embedding is a mapping $e:F_2^V\\to R^{N_d}$ (sparse vector, one-hot encoded, to dense real vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nd = 2                  # Number of Dimensions of the Dense embedding\n",
    "e = nn.Embedding(V,Nd)  # (vocab_size, num_of_dimensions_of_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first convert the coded sentences to Torch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " V x S : torch.Size([102, 4079]) (vocab. size x num. of sentences)\n",
      " Tensors of type torch.int64\n",
      " All encoded sentences as tensors (each column is a sentence):\n",
      "tensor([[   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [ 120,  120,   78,  ...,   20,  620, 2566],\n",
      "        [ 516,  611,   14,  ...,  255,    0,  297],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]])\n"
     ]
    }
   ],
   "source": [
    "coded_sentences = torch.LongTensor(wiki_crawler.coded_sentences).reshape(-1,T).T\n",
    "print(f' V x S : {coded_sentences.shape} (vocab. size x num. of sentences)')\n",
    "print(f' Tensors of type {coded_sentences.dtype}')\n",
    "print(' All encoded sentences as tensors (each column is a sentence):')\n",
    "print(coded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select, for example, the first sentence, as the varible $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([102])\n",
      "tensor([   1,  120,  516, 1182,    4,    0,   18,    5,  728,    3,   52, 1575,\n",
      "           0,    0,   31,  787,   19,    4,  120, 2665,  131, 2246,  788,    7,\n",
      "         211, 1023,   29, 1183,   31,  882,    7,   52,   50,   82,  288,    3,\n",
      "         120,  883,  131,  120,    0,   10, 1758,    2,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "c = coded_sentences[:,0]\n",
    "print(c.shape,c,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the sentence from sequences of one-hot-encoded words to its embedding vector.<br>\n",
    "When printing the corresponding sequence, we see that:\n",
    "- each index (one-hot-encoded word) is converted into a real row-vector of $N_d$ dimensions\n",
    "- the initialized embedding vectors are just random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([102, 2])\n",
      "tensor([[-0.6350,  0.4096],\n",
      "        [-0.3341, -0.3527],\n",
      "        [ 0.8590, -1.3855],\n",
      "        [-0.9808, -0.8642],\n",
      "        [ 1.2915, -0.6614],\n",
      "        [-0.2307,  1.2365],\n",
      "        [ 0.6716,  0.0221],\n",
      "        [ 0.3161,  0.6829],\n",
      "        [ 0.2401, -0.7691],\n",
      "        [ 1.9052, -0.8429]], grad_fn=<SliceBackward>)\n",
      "... and more words (truncated in the 10-th word).\n"
     ]
    }
   ],
   "source": [
    "e_seq = e(c)\n",
    "print(e_seq.shape,e_seq[:10,:],'... and more words (truncated in the 10-th word).',sep='\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a word to check its embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Word \"rainha\" corresponds to index 120\n",
      " Index 120 maps to embedding vector \"[-0.3340754210948944, -0.35269027948379517]\"\n"
     ]
    }
   ],
   "source": [
    "word    = 'rainha'\n",
    "\n",
    "idx     = wiki_crawler.word2idx[word] # uses dictionary to map word to index\n",
    "emb_vec = e(torch.LongTensor([idx]))  # uses torch embedding to map index to dense Nd-vector\n",
    "\n",
    "print(f' Word \"{word}\" corresponds to index {idx}')\n",
    "print(f' Index {idx} maps to embedding vector \"{emb_vec.detach().numpy().reshape(-1).tolist()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3003, 2]),\n",
       " torch.float32,\n",
       " tensor([[-0.2307,  1.2365],\n",
       "         [-0.6350,  0.4096],\n",
       "         [ 0.9973,  0.3776],\n",
       "         ...,\n",
       "         [-0.7678,  0.9854],\n",
       "         [-0.3680, -0.2005],\n",
       "         [ 0.3326,  0.2633]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = e.weight.data\n",
    "W1.shape, W1.dtype, W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Embeddings with Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag-of-Words (CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "context vs target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   1,  120,  516, 1182,    4,    0,   18,    5,  728,    3,   52, 1575,\n",
      "           0,    0,   31,  787,   19,    4,  120, 2665,  131, 2246,  788,    7,\n",
      "         211, 1023,   29, 1183,   31,  882,    7,   52,   50,   82,  288,    3,\n",
      "         120,  883,  131,  120,    0,   10, 1758,    2,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Left context: [], Middle word: 120, right context [516, 1182, 4, 0]\n",
      " Full context: [516, 1182, 4, 0]\n",
      " Words in context of ['rainha']: ['antigo', 'ray', 'a']\n",
      "\n",
      " Left context: [120], Middle word: 516, right context [1182, 4, 0]\n",
      " Full context: [120, 1182, 4, 0]\n",
      " Words in context of ['antigo']: ['rainha', 'ray', 'a']\n",
      "\n",
      " Left context: [120, 516], Middle word: 1182, right context [4, 0]\n",
      " Full context: [120, 516, 4, 0]\n",
      " Words in context of ['ray']: ['rainha', 'antigo', 'a']\n",
      "\n",
      " Left context: [516, 1182], Middle word: 4, right context [0, 18]\n",
      " Full context: [516, 1182, 0, 18]\n",
      " Words in context of ['a']: ['antigo', 'ray', 'é']\n",
      "\n",
      " Left context: [120, 883], Middle word: 131, right context [120, 0]\n",
      " Full context: [120, 883, 120, 0]\n",
      " Words in context of ['exemplo']: ['rainha', 'consorte', 'rainha']\n",
      "\n",
      " Left context: [883, 131], Middle word: 120, right context [0, 10]\n",
      " Full context: [883, 131, 0, 10]\n",
      " Words in context of ['rainha']: ['consorte', 'exemplo', 'da']\n",
      "\n",
      " Left context: [131, 120], Middle word: 0, right context [10, 1758]\n",
      " Full context: [131, 120, 10, 1758]\n",
      " Words in context of []: ['exemplo', 'rainha', 'da', 'suécia']\n",
      "\n",
      " Left context: [131, 120, 0], Middle word: 10, right context [1758]\n",
      " Full context: [131, 120, 0, 1758]\n",
      " Words in context of ['da']: ['exemplo', 'rainha', 'suécia']\n",
      "\n",
      " Left context: [131, 120, 0, 10], Middle word: 1758, right context []\n",
      " Full context: [131, 120, 0, 10]\n",
      " Words in context of ['suécia']: ['exemplo', 'rainha', 'da']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_size = 2\n",
    "end_position = (c==2).nonzero().item()\n",
    "\n",
    "samples_to_print = np.concatenate((np.arange(1,5),np.arange(end_position-5,end_position)),axis=0)\n",
    "for pos in samples_to_print: # range(1,end_position):\n",
    "    \n",
    "    middle_word   = c[pos]\n",
    "    \n",
    "    '''if middle_word==wiki_crawler.word2idx['<END>']:\n",
    "        break'''\n",
    "    \n",
    "    left_start = max(pos-context_size,1)\n",
    "    right_end  = min(pos+1+context_size,end_position)\n",
    "    \n",
    "    \n",
    "    if pos - left_start < context_size:                # first words position\n",
    "        right_end += context_size-(pos-left_start)     # --> increse right_context size\n",
    "    elif right_end-(pos+1) < context_size:             # last words position\n",
    "        left_start -= context_size-(right_end-(pos+1)) # --> increase left_context size\n",
    "            \n",
    "    left_context  = c[left_start:pos]\n",
    "    right_context = c[pos+1:right_end]\n",
    "    \n",
    "    context       = torch.cat((left_context,right_context),dim=0)\n",
    "    \n",
    "    print(f' Left context: {left_context.tolist()}, Middle word: {middle_word.tolist()}, right context {right_context.tolist()}')\n",
    "    print(f' Full context: {context.tolist()}')\n",
    "    \n",
    "    context_decoded     = wiki_crawler.decode_one_sentence(context.tolist())\n",
    "    middle_word_decoded = wiki_crawler.decode_one_sentence([middle_word.tolist()])\n",
    "    print(f' Words in context of {middle_word_decoded}: {context_decoded}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(coded_sentence, context_size):\n",
    "    \n",
    "    end_position = (c==2).nonzero().item()\n",
    "    target_context = []\n",
    "    for pos in range(1,end_position):\n",
    "        middle_word   = coded_sentence[pos]\n",
    "\n",
    "        left_start = max(pos-context_size,1)\n",
    "        right_end  = min(pos+1+context_size,end_position)\n",
    "\n",
    "        if pos - left_start < context_size:                # first words position\n",
    "            right_end += context_size-(pos-left_start)     # --> increse right_context size\n",
    "        elif right_end-(pos+1) < context_size:             # last words position\n",
    "            left_start -= context_size-(right_end-(pos+1)) # --> increase left_context size\n",
    "\n",
    "        left_context  = c[left_start:pos]\n",
    "        right_context = c[pos+1:right_end]\n",
    "        \n",
    "        context       = torch.cat((left_context,right_context),dim=0)\n",
    "        \n",
    "        target_context.append((middle_word.view((-1)),context))\n",
    "    return target_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language_Model_w2v(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, num_of_dimensions_of_embedding, context_size):\n",
    "        super(Language_Model_w2v, self).__init__()\n",
    "        self.V  = vocab_size\n",
    "        self.N  = num_of_dimensions_of_embedding \n",
    "        self.cs = context_size\n",
    "        \n",
    "        self.e  = nn.Embedding(self.V, self.N)\n",
    "        '''\n",
    "        self.W1 = nn.Linear(2*self.cs*self.N,128)\n",
    "        self.W2 = nn.Linear(128, self.V)\n",
    "        '''\n",
    "        # self.layers = nn.Sequential(*[self.e, self.W1, self.W2,self.LogSoftMax])\n",
    "        \n",
    "        self.Winv = nn.Linear(self.N, self.V)\n",
    "        self.LogSoftMax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):               # x is 2*cs x 1\n",
    "        x = self.e(x)\n",
    "        x = x.sum(dim=0).view(1,-1)\n",
    "        x = self.Winv(x)\n",
    "        x = self.LogSoftMax(x)\n",
    "        \n",
    "        return x\n",
    "        ''' \n",
    "        x = self.e(x).view((1,-1))     # e(x) 2*cs x N\n",
    "        x = self.W1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.W2(x)\n",
    "        log_probs = self.LogSoftMax(x)\n",
    "        return log_probs\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 5\n",
    "print_iters = 50\n",
    "cs = 3\n",
    "Nd = 10\n",
    "losses    = []\n",
    "criterion = nn.NLLLoss()\n",
    "model     = Language_Model_w2v(V, num_of_dimensions_of_embedding=Nd, context_size=cs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) # optim.SGD(model.parameters(),lr=1e-3) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language_Model_w2v(\n",
       "  (e): Embedding(3003, 10)\n",
       "  (Winv): Linear(in_features=10, out_features=3003, bias=True)\n",
       "  (LogSoftMax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    cnt = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    coded_sentences = coded_sentences[:,np.random.permutation(S)]\n",
    "    \n",
    "    for n in range(S):\n",
    "        \n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words into integer indices and wrap them in tensors)\n",
    "        c = coded_sentences[:,n]\n",
    "        \n",
    "        pos_cnt = 0\n",
    "        for target, context in get_context(c, cs):\n",
    "            pos_cnt += 1\n",
    "            if len(context)<2*cs:\n",
    "                continue\n",
    "            \n",
    "            # Step 2. Recall that torch *accumulates* gradients. \n",
    "            # Before passing in a new instance, you need to zero out the gradients from the oldinstance\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # Step 3. Run the forward pass, getting log probabilities over next words\n",
    "            log_probs = model(context)  \n",
    "            \n",
    "            # Step 4. Compute your loss function. \n",
    "            # (Again, Torch wants the target word wrapped in a tensor)\n",
    "            loss = criterion(log_probs, target)\n",
    "\n",
    "            # Step 5. Do the backward pass and update the gradient\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "            total_loss += loss.item()/T/S\n",
    "            \n",
    "        cnt+=1\n",
    "        if n%print_iters==1:\n",
    "            print(f'epoch {epoch} sentence {n}/{S} loss: {total_loss:.5f}')\n",
    "    print(f'loss: {total_loss:.6f}')\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    time.sleep(1.5)\n",
    "    clear_output()\n",
    "#print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_cnt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_probs.data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for group in model.parameters():\n",
    "    print(group.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x289e9651278>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/html": [
       "\n",
       "\n",
       "<style>\n",
       "\n",
       "</style>\n",
       "\n",
       "<div id=\"fig_el1650427913492124403002414449\"></div>\n",
       "<script>\n",
       "function mpld3_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(mpld3) !== \"undefined\" && mpld3._mpld3IsLoaded){\n",
       "   // already loaded: just create the figure\n",
       "   !function(mpld3){\n",
       "       \n",
       "       mpld3.draw_figure(\"fig_el1650427913492124403002414449\", {\"width\": 792.0, \"height\": 288.0, \"axes\": [{\"bbox\": [0.125, 0.125, 0.775, 0.755], \"xlim\": [-0.2, 4.2], \"ylim\": [1.8106936077903049, 1.8758337824756115], \"xdomain\": [-0.2, 4.2], \"ydomain\": [1.8106936077903049, 1.8758337824756115], \"xscale\": \"linear\", \"yscale\": \"linear\", \"axes\": [{\"position\": \"bottom\", \"nticks\": 11, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}, {\"position\": \"left\", \"nticks\": 8, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}], \"axesbg\": \"#FFFFFF\", \"axesbgalpha\": null, \"zoomable\": true, \"id\": \"el165042791349212272\", \"lines\": [{\"data\": \"data01\", \"xindex\": 0, \"yindex\": 1, \"coordinates\": \"data\", \"id\": \"el165042791349490296\", \"color\": \"#1F77B4\", \"linewidth\": 1.5, \"dasharray\": \"none\", \"alpha\": 1, \"zorder\": 2, \"drawstyle\": \"default\"}], \"paths\": [], \"markers\": [], \"texts\": [], \"collections\": [], \"images\": [], \"sharex\": [], \"sharey\": []}], \"data\": {\"data01\": [[0.0, 1.8570255352635139], [1.0, 1.8728728654444613], [2.0, 1.8470118732472174], [3.0, 1.8328236584601596], [4.0, 1.813654524821455]]}, \"id\": \"el165042791349212440\", \"plugins\": [{\"type\": \"reset\"}, {\"type\": \"zoom\", \"button\": true, \"enabled\": false}, {\"type\": \"boxzoom\", \"button\": true, \"enabled\": false}]});\n",
       "   }(mpld3);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/mpld3\n",
       "   require.config({paths: {d3: \"https://mpld3.github.io/js/d3.v3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      mpld3_load_lib(\"https://mpld3.github.io/js/mpld3.v0.3.1.dev1.js\", function(){\n",
       "         \n",
       "         mpld3.draw_figure(\"fig_el1650427913492124403002414449\", {\"width\": 792.0, \"height\": 288.0, \"axes\": [{\"bbox\": [0.125, 0.125, 0.775, 0.755], \"xlim\": [-0.2, 4.2], \"ylim\": [1.8106936077903049, 1.8758337824756115], \"xdomain\": [-0.2, 4.2], \"ydomain\": [1.8106936077903049, 1.8758337824756115], \"xscale\": \"linear\", \"yscale\": \"linear\", \"axes\": [{\"position\": \"bottom\", \"nticks\": 11, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}, {\"position\": \"left\", \"nticks\": 8, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}], \"axesbg\": \"#FFFFFF\", \"axesbgalpha\": null, \"zoomable\": true, \"id\": \"el165042791349212272\", \"lines\": [{\"data\": \"data01\", \"xindex\": 0, \"yindex\": 1, \"coordinates\": \"data\", \"id\": \"el165042791349490296\", \"color\": \"#1F77B4\", \"linewidth\": 1.5, \"dasharray\": \"none\", \"alpha\": 1, \"zorder\": 2, \"drawstyle\": \"default\"}], \"paths\": [], \"markers\": [], \"texts\": [], \"collections\": [], \"images\": [], \"sharex\": [], \"sharey\": []}], \"data\": {\"data01\": [[0.0, 1.8570255352635139], [1.0, 1.8728728654444613], [2.0, 1.8470118732472174], [3.0, 1.8328236584601596], [4.0, 1.813654524821455]]}, \"id\": \"el165042791349212440\", \"plugins\": [{\"type\": \"reset\"}, {\"type\": \"zoom\", \"button\": true, \"enabled\": false}, {\"type\": \"boxzoom\", \"button\": true, \"enabled\": false}]});\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & mpld3\n",
       "    mpld3_load_lib(\"https://mpld3.github.io/js/d3.v3.min.js\", function(){\n",
       "         mpld3_load_lib(\"https://mpld3.github.io/js/mpld3.v0.3.1.dev1.js\", function(){\n",
       "                 \n",
       "                 mpld3.draw_figure(\"fig_el1650427913492124403002414449\", {\"width\": 792.0, \"height\": 288.0, \"axes\": [{\"bbox\": [0.125, 0.125, 0.775, 0.755], \"xlim\": [-0.2, 4.2], \"ylim\": [1.8106936077903049, 1.8758337824756115], \"xdomain\": [-0.2, 4.2], \"ydomain\": [1.8106936077903049, 1.8758337824756115], \"xscale\": \"linear\", \"yscale\": \"linear\", \"axes\": [{\"position\": \"bottom\", \"nticks\": 11, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}, {\"position\": \"left\", \"nticks\": 8, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}], \"axesbg\": \"#FFFFFF\", \"axesbgalpha\": null, \"zoomable\": true, \"id\": \"el165042791349212272\", \"lines\": [{\"data\": \"data01\", \"xindex\": 0, \"yindex\": 1, \"coordinates\": \"data\", \"id\": \"el165042791349490296\", \"color\": \"#1F77B4\", \"linewidth\": 1.5, \"dasharray\": \"none\", \"alpha\": 1, \"zorder\": 2, \"drawstyle\": \"default\"}], \"paths\": [], \"markers\": [], \"texts\": [], \"collections\": [], \"images\": [], \"sharex\": [], \"sharey\": []}], \"data\": {\"data01\": [[0.0, 1.8570255352635139], [1.0, 1.8728728654444613], [2.0, 1.8470118732472174], [3.0, 1.8328236584601596], [4.0, 1.813654524821455]]}, \"id\": \"el165042791349212440\", \"plugins\": [{\"type\": \"reset\"}, {\"type\": \"zoom\", \"button\": true, \"enabled\": false}, {\"type\": \"boxzoom\", \"button\": true, \"enabled\": false}]});\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e.weight torch.Size([3003, 10])\n",
      "Winv.weight torch.Size([3003, 10])\n",
      "Winv.bias torch.Size([3003])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape) # param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3003, 10]),\n",
       " tensor([[ 2.9594e-01, -6.8543e-02, -1.6310e-01,  ..., -2.2459e-01,\n",
       "           1.7763e-01,  7.1652e-01],\n",
       "         [ 1.2123e-01,  1.7437e-01, -9.9919e-02,  ..., -1.6410e+00,\n",
       "          -9.3114e-01, -2.7260e-01],\n",
       "         [-1.7299e+00, -1.7535e-01, -3.1855e-01,  ...,  3.4555e-01,\n",
       "           1.9645e-01,  1.5670e-01],\n",
       "         ...,\n",
       "         [-2.5660e+00,  1.7125e+00,  1.0468e+00,  ..., -1.3669e-03,\n",
       "           8.5296e-02,  5.5529e-01],\n",
       "         [-5.5270e-01, -1.3120e-01, -1.7963e+00,  ...,  3.4877e-01,\n",
       "          -8.5716e-01, -2.8250e-01],\n",
       "         [-1.3551e+00,  5.7612e-01,  3.7605e-01,  ...,  1.5092e+00,\n",
       "           2.2110e+00, -2.8951e-01]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding = model.e.weight.data\n",
    "Embedding.shape, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_analogy(pos_neg_1=('king','man'),pos_neg_2=('queen','woman'), n_closest = 4):\n",
    "    king_w,    man_w = pos_neg_1\n",
    "    queen_w, woman_w = pos_neg_2\n",
    "    \n",
    "    for w in (king_w,man_w,woman_w):\n",
    "        if w not in wiki_crawler.word2idx:\n",
    "            raise Exception(f'sorry, word \"{w}\" not in dictionary.')\n",
    "    \n",
    "    print(f'Expected: {king_w} - {man_w} = {queen_w} - {woman_w}')\n",
    "    \n",
    "    king   = wiki_crawler.word2idx[king_w]\n",
    "    man    = wiki_crawler.word2idx[man_w]\n",
    "    woman  = wiki_crawler.word2idx[woman_w]\n",
    "    \n",
    "    vec = (Embedding[king] - Embedding[man] + Embedding[woman]).view(1,-1) # Embedding[queen]\n",
    "    distances = pairwise_distances(vec.reshape(1, -1), Embedding, metric='cosine').reshape(V)\n",
    "    \n",
    "    idx = distances.argsort()[:n_closest+3] \n",
    "    idx = [x for x in idx if x not in set([man,king,woman])]\n",
    "    queen_estimated = wiki_crawler.idx2word[idx[0]]\n",
    "    \n",
    "    print(f'Got:      {king_w} - {man_w} = {queen_estimated} - {woman_w}')\n",
    "    \n",
    "    print(f'Closest {len(idx)} words:')\n",
    "    for i in idx:\n",
    "        print(f'{wiki_crawler.idx2word[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: rei - homem = rainha - mulher\n",
      "Got:      rei - homem = espaço - mulher\n",
      "Closest 6 words:\n",
      "espaço\n",
      "fundamental\n",
      "restauração\n",
      "dada\n",
      "simples\n",
      "termos\n"
     ]
    }
   ],
   "source": [
    "word_analogy(pos_neg_1=('rei','homem'),pos_neg_2=('rainha','mulher'), n_closest = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: rei - príncipe = rainha - princesa\n",
      "Got:      rei - príncipe = observou - princesa\n",
      "Closest 7 words:\n",
      "observou\n",
      "princípio\n",
      "superior\n",
      "feira\n",
      "nuclear\n",
      "personagem\n",
      "circunstâncias\n"
     ]
    }
   ],
   "source": [
    "word_analogy(pos_neg_1=('rei','príncipe'),pos_neg_2=('rainha','princesa'), n_closest = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: homem - mulher = ele - ela\n",
      "Got:      homem - mulher = trabalhando - ela\n",
      "Closest 6 words:\n",
      "trabalhando\n",
      "vale\n",
      "chinês\n",
      "seguindo\n",
      "estando\n",
      "gato\n"
     ]
    }
   ],
   "source": [
    "word_analogy(pos_neg_1=('homem','mulher'),pos_neg_2=('ele','ela'), n_closest = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: homem - mulher = marido - esposa\n",
      "Got:      homem - mulher = trabalhando - esposa\n",
      "Closest 6 words:\n",
      "trabalhando\n",
      "pertencente\n",
      "olímpicos\n",
      "diretor\n",
      "objetivo\n",
      "esforço\n"
     ]
    }
   ],
   "source": [
    "word_analogy(pos_neg_1=('homem','mulher'),pos_neg_2=('marido','esposa'), n_closest = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: brasil - brasileiro = japão - japonês\n",
      "Got:      brasil - brasileiro = filme - japonês\n",
      "Closest 7 words:\n",
      "filme\n",
      "papel\n",
      "jogo\n",
      "esporte\n",
      "projeto\n",
      "afirmou\n",
      "perde\n"
     ]
    }
   ],
   "source": [
    "word_analogy(pos_neg_1=('brasil','brasileiro'),pos_neg_2=('japão','japonês'), n_closest = 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_negative_sampling_distribution(coded_sentences, V):\n",
    "    # Pn(w) = prob of word occuring\n",
    "    # we would like to sample the negative samples such that \n",
    "    # words that occur more often should be sampled more often\n",
    "    \n",
    "    freq  = np.zeros(V)                 # vector with V positions\n",
    "    for c in coded_sentences:\n",
    "        for w in c:\n",
    "            freq[w] += 1          # it is assumed that each word is actually its OHE index\n",
    "\n",
    "    f_neg = freq**0.75     # smoothing\n",
    "    pmf_neg = f_neg / f_neg.sum() # normalized pmf\n",
    "    \n",
    "    assert(np.all(pmf_neg > 0)) # check that only positive probabilities were drawn\n",
    "    \n",
    "    return pmf_neg\n",
    "\n",
    "# distribution for drawing negative samples\n",
    "pmf_neg = get_negative_sampling_distribution(wiki_crawler.coded_sentences, V) \n",
    "\n",
    "# for subsampling each sentence\n",
    "threshold = 1e-5 # 1 em 100.000\n",
    "p_drop = 1 - np.sqrt(threshold / pmf_neg)  # prob. de ignorar uma palavra :: aumenta conforme a frequência dessa palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
