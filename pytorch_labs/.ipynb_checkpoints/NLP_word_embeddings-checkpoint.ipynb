{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NLP Word Embeddings with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/50747947/embedding-in-pytorch\n",
    "# https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wikipedia\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "#!pip install --user \"git+https://github.com/javadba/mpld3@display_fix\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web-Scraper collects corpus from Wikipedia in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Wikipedia_Crawler` class uses the `wikipedia` module to load a _corpus_ in real time.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_labs.my_nlp_classes import Wikipedia_Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to set the desired language of the searches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang('pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will search specific wikis from the input query and downloads its content.\n",
    "- `query_list` is the list of query text to look for in Wikipedia\n",
    "- `max_results` is the maximum number of pages to load per query expression in the `query_list`\n",
    "- `max_v` will be used later to limit the vocabulary size of our custom dictionary\n",
    "- `skip_top` is the number of most frequent words (descending order) to be discard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list  = ['Rainha','Rei','Mulher','Homem','Brasil','Japão','Família','Tempo','Calendário'] #  \n",
    "max_results = 3\n",
    "max_V       = 3000\n",
    "skip_top    = 0\n",
    "max_len_sentence = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell, we instantiate the crawler with its basic query parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_crawler = Wikipedia_Crawler(query_list=query_list,max_results_per_query=max_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the desired wiki pages, we call for `query_wiki`. <br>\n",
    "The methods `get_wiki_sentences` downloads and tokenizes the sentences of the pages. <br> \n",
    "Then, `get_all_tokens` lists all unique tokens (words) in the data. Tokenization is performed in the process. <br>\n",
    "Finally, `count_vocabulary` counts the absolute frequency of each token. Tokenization is performed in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_crawler.query_wiki()\n",
    "wiki_crawler.get_wiki_sentences()\n",
    "wiki_crawler.get_all_tokens()\n",
    "wiki_crawler.count_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the tokens may be prohibitive. Thus, it is necessary to limit the vocabulary. <br>\n",
    "- `generate_vocabulary` will create `word2idx` and `idx2word` dictionaries \n",
    "- - dictionaries will be limited with `max_V` words ($+ 3$ tags)\n",
    "- - note that `skip_top` most frequent words will be discarded\n",
    "- `encode_all_sentence` will encode sentences of words into sequences (lists) of corresponding indexes\n",
    "- - encoded sentences will have additional `\"<START>\"` and `\"<END>\"` tokens\n",
    "- - words out of vocabulary will be coded with index of `\"<OOV>\"` tag\n",
    "- - encoded senteces will be truncated with `max_len_sentence` actual words ($+ 2$ start/end tags)\n",
    "- - encoded senteces padded by default, unless `pad_sentences` is set to `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_crawler.generate_vocabulary(max_len_vocabulary=max_V, skip_top_words=skip_top)\n",
    "wiki_crawler.encode_all_sentence(max_len_sentence=max_len_sentence, pad_sentences=True) # pad_sentences is True by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check where did the corpus came from and other results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Corpus derived from the following wiki pages: \n",
      " ---- ['Rainha', 'Homem', 'História', 'Europa', 'Monarquia']\n",
      " Number of sentences: ------ 704\n",
      " Max. words in sentence: --- 50\n",
      " Vocabulary Size: ---------- 2003\n"
     ]
    }
   ],
   "source": [
    "S = len(wiki_crawler.sentences)           \n",
    "T = len(wiki_crawler.coded_sentences[0]) # max_len_sentence + 2\n",
    "V = len(wiki_crawler.word2idx)           # max_V + 2\n",
    "\n",
    "print(f' Corpus derived from the following wiki pages: \\n ---- {wiki_crawler.titles_list}')\n",
    "print(f' Number of sentences: ------ {S}')\n",
    "print(f' Max. words in sentence: --- {T-2}')\n",
    "print(f' Vocabulary Size: ---------- {V}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we can check the generated sentences.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Real Text sentence: \n",
      "    entre os reis davi de judá e israel, não é mencionado uma única rainha reinante; apesar de atália, embora a bíblia se refira negativamente como uma usurpadora.\n",
      "\n",
      " Encoded Sentence: \n",
      "    [1, 42, 11, 276, 1724, 4, 1725, 5, 1059, 36, 16, 1726, 19, 277, 78, 177, 150, 4, 1727, 160, 3, 1060, 15, 1728, 1729, 18, 19, 1730, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      " Decoded Sentence: \n",
      "    <START> entre os reis davi de judá e israel não é mencionado uma única rainha reinante apesar de atália embora a bíblia se refira negativamente como uma usurpadora <END>\n"
     ]
    }
   ],
   "source": [
    "num_sentence = 5\n",
    "\n",
    "real_sentence    = wiki_crawler.sentences[num_sentence]\n",
    "encoded_sentece  = wiki_crawler.coded_sentences[num_sentence]\n",
    "decoded_sentence = wiki_crawler.decode_one_sentence(encoded_sentece)\n",
    "\n",
    "print(f' Real Text sentence: \\n    {real_sentence}', end=2*'\\n')\n",
    "print(f' Encoded Sentence: \\n    {encoded_sentece}', end=2*'\\n')\n",
    "print(f' Decoded Sentence: \\n    '+' '.join(decoded_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can see how to use the dictionary directly to convert `wor2idx` or `idx2word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Word \"mulher\" corresponds to index 365\n",
      " Index 9 corresponds to word \"em\"\n"
     ]
    }
   ],
   "source": [
    "word = 'mulher'\n",
    "idx = 9\n",
    "print(f' Word \"{word}\" corresponds to index {wiki_crawler.word2idx[word]}')\n",
    "print(f' Index {idx} corresponds to word \"{wiki_crawler.idx2word[idx]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll see how to use the ``Embedding`` layer of Torch. <br>\n",
    "It converts categorical data with $V$ classes to dense vectors with $N_d$ dimensions. <br>\n",
    "Suppose $c\\in{F_2^V}$ is a one-hot encoded vector. <br>\n",
    "An embedding is a mapping $e:F_2^V\\to R^{N_d}$ (sparse vector, one-hot encoded, to dense real vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nd = 2                  # Number of Dimensions of the Dense embedding\n",
    "e = nn.Embedding(V,Nd)  # (vocab_size, num_of_dimensions_of_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first convert the coded sentences to Torch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " V x S : torch.Size([52, 704]) (vocab. size x num. of sentences)\n",
      " Tensors of type torch.int64\n",
      " All encoded sentences as tensors (each column is a sentence):\n",
      "tensor([[  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [ 78,  78,  33,  ...,  97, 502,   3],\n",
      "        [321, 177,  13,  ...,   3,  31, 761],\n",
      "        ...,\n",
      "        [  0,  38,   0,  ...,   0,   0,   0],\n",
      "        [  0, 177,   0,  ...,   0,   0,   0],\n",
      "        [  0,   2,   0,  ...,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "coded_sentences = torch.LongTensor(wiki_crawler.coded_sentences).reshape(-1,T).T\n",
    "print(f' V x S : {coded_sentences.shape} (vocab. size x num. of sentences)')\n",
    "print(f' Tensors of type {coded_sentences.dtype}')\n",
    "print(' All encoded sentences as tensors (each column is a sentence):')\n",
    "print(coded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select, for example, the first sentence, as the varible $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52])\n",
      "tensor([   1,   78,  321, 1700,    3, 1701,   16,    6,  767,    4,   43, 1702,\n",
      "        1703, 1704,   35,   38,   18,    3,   78, 1050,   79, 1051,  222,    8,\n",
      "          49,   72,   26, 1052,   35,  768,    8,   43,   69,  124,  223,    4,\n",
      "          78,  358,   79,   78, 1705,    7,  125,    2,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "c = coded_sentences[:,0]\n",
    "print(c.shape,c,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the sentence from sequences of one-hot-encoded words to its embedding vector.<br>\n",
    "When printing the corresponding sequence, we see that:\n",
    "- each index (one-hot-encoded word) is converted into a real row-vector of $N_d$ dimensions\n",
    "- the initialized embedding vectors are just random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 2])\n",
      "tensor([[-0.0351,  0.2174],\n",
      "        [-0.0178, -0.6732],\n",
      "        [-0.0542, -0.3355],\n",
      "        [ 1.0331, -0.4499],\n",
      "        [-0.2469,  0.4797],\n",
      "        [-1.5759,  0.8275],\n",
      "        [ 0.5124, -0.5508],\n",
      "        [ 0.8539, -0.4127],\n",
      "        [ 0.5920, -0.7205],\n",
      "        [ 0.2396, -0.3507]], grad_fn=<SliceBackward>)\n",
      "... and more words (truncated in the 10-th word).\n"
     ]
    }
   ],
   "source": [
    "e_seq = e(c)\n",
    "print(e_seq.shape,e_seq[:10,:],'... and more words (truncated in the 10-th word).',sep='\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a word to check its embedding vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Word \"rainha\" corresponds to index 78\n",
      " Index 78 maps to embedding vector \"[-0.017817500978708267, -0.6731522679328918]\"\n"
     ]
    }
   ],
   "source": [
    "word    = 'rainha'\n",
    "\n",
    "idx     = wiki_crawler.word2idx[word] # uses dictionary to map word to index\n",
    "emb_vec = e(torch.LongTensor([idx]))  # uses torch embedding to map index to dense Nd-vector\n",
    "\n",
    "print(f' Word \"{word}\" corresponds to index {idx}')\n",
    "print(f' Index {idx} maps to embedding vector \"{emb_vec.detach().numpy().reshape(-1).tolist()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2003, 2]),\n",
       " torch.float32,\n",
       " tensor([[-0.2898,  2.2263],\n",
       "         [-0.0351,  0.2174],\n",
       "         [-0.8900, -1.8887],\n",
       "         ...,\n",
       "         [ 0.3717, -0.4304],\n",
       "         [ 0.4716,  0.2191],\n",
       "         [-0.5981, -0.0149]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = e.weight.data\n",
    "W1.shape, W1.dtype, W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Embeddings with Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag-of-Words (CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "context vs target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   1,   78,  321, 1700,    3, 1701,   16,    6,  767,    4,   43, 1702,\n",
      "        1703, 1704,   35,   38,   18,    3,   78, 1050,   79, 1051,  222,    8,\n",
      "          49,   72,   26, 1052,   35,  768,    8,   43,   69,  124,  223,    4,\n",
      "          78,  358,   79,   78, 1705,    7,  125,    2,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Left context: [], Middle word: 78, right context [321, 1700, 3, 1701]\n",
      " Full context: [321, 1700, 3, 1701]\n",
      " Words in context of ['rainha']: ['antigo', 'ray', 'a', 'reynna']\n",
      "\n",
      " Left context: [78], Middle word: 321, right context [1700, 3, 1701]\n",
      " Full context: [78, 1700, 3, 1701]\n",
      " Words in context of ['antigo']: ['rainha', 'ray', 'a', 'reynna']\n",
      "\n",
      " Left context: [78, 321], Middle word: 1700, right context [3, 1701]\n",
      " Full context: [78, 321, 3, 1701]\n",
      " Words in context of ['ray']: ['rainha', 'antigo', 'a', 'reynna']\n",
      "\n",
      " Left context: [321, 1700], Middle word: 3, right context [1701, 16]\n",
      " Full context: [321, 1700, 1701, 16]\n",
      " Words in context of ['a']: ['antigo', 'ray', 'reynna', 'é']\n",
      "\n",
      " Left context: [78, 358], Middle word: 79, right context [78, 1705]\n",
      " Full context: [78, 358, 78, 1705]\n",
      " Words in context of ['exemplo']: ['rainha', 'consorte', 'rainha', 'silvia']\n",
      "\n",
      " Left context: [358, 79], Middle word: 78, right context [1705, 7]\n",
      " Full context: [358, 79, 1705, 7]\n",
      " Words in context of ['rainha']: ['consorte', 'exemplo', 'silvia', 'da']\n",
      "\n",
      " Left context: [79, 78], Middle word: 1705, right context [7, 125]\n",
      " Full context: [79, 78, 7, 125]\n",
      " Words in context of ['silvia']: ['exemplo', 'rainha', 'da', 'suécia']\n",
      "\n",
      " Left context: [79, 78, 1705], Middle word: 7, right context [125]\n",
      " Full context: [79, 78, 1705, 125]\n",
      " Words in context of ['da']: ['exemplo', 'rainha', 'silvia', 'suécia']\n",
      "\n",
      " Left context: [79, 78, 1705, 7], Middle word: 125, right context []\n",
      " Full context: [79, 78, 1705, 7]\n",
      " Words in context of ['suécia']: ['exemplo', 'rainha', 'silvia', 'da']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_size = 2\n",
    "end_position = (c==2).nonzero().item()\n",
    "\n",
    "samples_to_print = np.concatenate((np.arange(1,5),np.arange(end_position-5,end_position)),axis=0)\n",
    "for pos in samples_to_print: # range(1,end_position):\n",
    "    \n",
    "    middle_word   = c[pos]\n",
    "    \n",
    "    '''if middle_word==wiki_crawler.word2idx['<END>']:\n",
    "        break'''\n",
    "    \n",
    "    left_start = max(pos-context_size,1)\n",
    "    right_end  = min(pos+1+context_size,end_position)\n",
    "    \n",
    "    \n",
    "    if pos - left_start < context_size:                # first words position\n",
    "        right_end += context_size-(pos-left_start)     # --> increse right_context size\n",
    "    elif right_end-(pos+1) < context_size:             # last words position\n",
    "        left_start -= context_size-(right_end-(pos+1)) # --> increase left_context size\n",
    "            \n",
    "    left_context  = c[left_start:pos]\n",
    "    right_context = c[pos+1:right_end]\n",
    "    \n",
    "    context       = torch.cat((left_context,right_context),dim=0)\n",
    "    \n",
    "    print(f' Left context: {left_context.tolist()}, Middle word: {middle_word.tolist()}, right context {right_context.tolist()}')\n",
    "    print(f' Full context: {context.tolist()}')\n",
    "    \n",
    "    context_decoded     = wiki_crawler.decode_one_sentence(context.tolist())\n",
    "    middle_word_decoded = wiki_crawler.decode_one_sentence([middle_word.tolist()])\n",
    "    print(f' Words in context of {middle_word_decoded}: {context_decoded}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(coded_sentence, context_size):\n",
    "    \n",
    "    end_position = (c==2).nonzero().item()\n",
    "    target_context = []\n",
    "    for pos in range(1,end_position):\n",
    "        middle_word   = coded_sentence[pos]\n",
    "\n",
    "        left_start = max(pos-context_size,1)\n",
    "        right_end  = min(pos+1+context_size,end_position)\n",
    "\n",
    "        if pos - left_start < context_size:                # first words position\n",
    "            right_end += context_size-(pos-left_start)     # --> increse right_context size\n",
    "        elif right_end-(pos+1) < context_size:             # last words position\n",
    "            left_start -= context_size-(right_end-(pos+1)) # --> increase left_context size\n",
    "\n",
    "        left_context  = c[left_start:pos]\n",
    "        right_context = c[pos+1:right_end]\n",
    "        \n",
    "        context       = torch.cat((left_context,right_context),dim=0)\n",
    "        \n",
    "        target_context.append((middle_word.view((-1)),context))\n",
    "    return target_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language_Model_w2v(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, num_of_dimensions_of_embedding, context_size):\n",
    "        super(Language_Model_w2v, self).__init__()\n",
    "        self.V  = vocab_size\n",
    "        self.N  = num_of_dimensions_of_embedding \n",
    "        self.cs = context_size\n",
    "        \n",
    "        self.e  = nn.Embedding(self.V, self.N)\n",
    "        '''\n",
    "        self.W1 = nn.Linear(2*self.cs*self.N,128)\n",
    "        self.W2 = nn.Linear(128, self.V)\n",
    "        '''\n",
    "        # self.layers = nn.Sequential(*[self.e, self.W1, self.W2,self.LogSoftMax])\n",
    "        \n",
    "        self.Winv = nn.Linear(self.N, self.V)\n",
    "        self.LogSoftMax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):               # x is 2*cs x 1\n",
    "        x = self.e(x)\n",
    "        x = x.sum(dim=0).view(1,-1)\n",
    "        x = self.Winv(x)\n",
    "        x = self.LogSoftMax(x)\n",
    "        \n",
    "        return x\n",
    "        ''' \n",
    "        x = self.e(x).view((1,-1))     # e(x) 2*cs x N\n",
    "        x = self.W1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.W2(x)\n",
    "        log_probs = self.LogSoftMax(x)\n",
    "        return log_probs\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 5\n",
    "print_iters = 50\n",
    "cs = 3\n",
    "Nd = 10\n",
    "losses    = []\n",
    "criterion = nn.NLLLoss()\n",
    "model     = Language_Model_w2v(V, num_of_dimensions_of_embedding=Nd, context_size=cs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) # optim.SGD(model.parameters(),lr=1e-3) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language_Model_w2v(\n",
       "  (e): Embedding(2003, 10)\n",
       "  (Winv): Linear(in_features=10, out_features=2003, bias=True)\n",
       "  (LogSoftMax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    cnt = 0\n",
    "    total_loss = 0\n",
    "    \n",
    "    coded_sentences = coded_sentences[:,np.random.permutation(S)]\n",
    "    \n",
    "    for n in range(S):\n",
    "        \n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words into integer indices and wrap them in tensors)\n",
    "        c = coded_sentences[:,n]\n",
    "        \n",
    "        pos_cnt = 0\n",
    "        for target, context in get_context(c, cs):\n",
    "            pos_cnt+=1\n",
    "            if len(context)<2*cs:\n",
    "                continue\n",
    "            \n",
    "            # Step 2. Recall that torch *accumulates* gradients. \n",
    "            # Before passing in a new instance, you need to zero out the gradients from the oldinstance\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # Step 3. Run the forward pass, getting log probabilities over next words\n",
    "            log_probs = model(context)  \n",
    "            \n",
    "            # Step 4. Compute your loss function. \n",
    "            # (Again, Torch wants the target word wrapped in a tensor)\n",
    "            loss = criterion(log_probs, target)\n",
    "\n",
    "            # Step 5. Do the backward pass and update the gradient\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "            total_loss += loss.item()/T/S\n",
    "            \n",
    "        cnt+=1\n",
    "        if n%print_iters==1:\n",
    "            print(f'epoch {epoch} sentence {n}/{S} loss: {total_loss*(T/pos_cnt):.5f}')\n",
    "    print(f'loss: {total_loss:.6f}')\n",
    "    losses.append(total_loss)\n",
    "    \n",
    "    time.sleep(1.5)\n",
    "    clear_output()\n",
    "#print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_probs.data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for group in model.parameters():\n",
    "    print(group.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18cb6600438>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApEAAAD4CAYAAAC0T71wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxcdb3/8fdnZrI2adIl3TeQlgKFtnQoeFHuFVALeEH4sQtUL1BRERW8/hS3C+5eRUVQKMvvtmyyKMgF0Vs2Ea4CSWlL9xbKUrqlS5qkbZZJPr8/5rQk00kzadOcSeb1fDzmMTPnfM/MZ76P08y733O+c8zdBQAAAHRFJOwCAAAA0PsQIgEAANBlhEgAAAB0GSESAAAAXUaIBAAAQJfFwi4gncGDB/u4cePCLgMAACCnVVVVbXb3inTrsjJEjhs3TpWVlWGXAQAAkNPM7O2O1nE4GwAAAF1GiAQAAECXdRoizazQzF4xs4VmtsTMbkjT5lozW2pmi8zsGTMb22bdTDNbFdxmdvcHAAAAQM/LZCSyUdLJ7j5Z0hRJM8zshJQ2r0mKu/sxkh6R9FNJMrOBkr4r6XhJ0yV918wGdFfxAAAACEenIdKT6oOnecHNU9o85+47g6f/kDQqePxxSfPcfau7b5M0T9KMbqkcAAAAocnonEgzi5rZAkmblAyFL++j+eWSngoej5T0bpt1a4Nl6d5jlplVmllldXV1JmUBAAAgJBmFSHdvcfcpSo4wTjezSenamdklkuKS/nP3onQv18F7zHb3uLvHKyrS/hwRAAAAskSXZme7e42k55XmkLSZnSrpm5LOdPfGYPFaSaPbNBslad1+VXoQbNvRpP94fIl2NbWEXQoAAECvksns7AozKw8eF0k6VdLylDZTJd2uZIDc1GbVXyR9zMwGBBNqPhYsywqL3tuuOX9/S//+yEK5px0gBQAAQBqZjEQOl/ScmS2S9KqS50Q+YWY3mtmZQZv/lFQi6WEzW2Bmj0uSu2+V9L1gu1cl3Rgsywr/PKFCX/v4RD2xaL1ueXZ12OUAAAD0Gp1e9tDdF0mammb5d9o8PnUf298t6e79LfBgu+qfD9XKjXX6+byVGj+0VDMmDQu7JAAAgKyX81esMTP96JyjNXl0ua59aIGWra8NuyQAAICsl/MhUpIK86Kafek0lRbGdMWcSm2pb+x8IwAAgBxGiAwM7V+o2ZfGtbm+UZ+7d76aEq1hlwQAAJC1CJFtTB5drp+ee4xeeWurvvv4YmZsAwAAdKDTiTW55qwpI7ViQ51+8/wbOnxoqT594iFhlwQAAJB1GIlM46sfO1ynHjFU33tymV5ctTnscgAAALIOITKNSMT0ywun6LCKEn3+viqt2bwj7JIAAACyCiGyAyUFMd05M65oxHTFnFdV29AcdkkAAABZgxC5D6MHFuu3l0zT21t26poHXlNLKxNtAAAAJEJkp044dJBuOOsoPb+iWj/58/LONwAAAMgBzM7OwKeOH6vl6+s0+4U3NWFoqc6dNirskgAAAELFSGSGvvOvR+qDhw7S9X94XVVvbwu7HAAAgFARIjOUF43oN586VsPLC/XZe6q0rmZX2CUBAACEhhDZBQP65evOy+JqaG7RrHsqtaupJeySAAAAQkGI7KLxQ0t180VTtGRdrb76yEIujQgAAHISIXI/nDxxqP7vjIl6ctF6/frZ1WGXAwAA0OOYnb2fPnvSoVq5oU43zVupCUNLNGPS8LBLAgAA6DGMRO4nM9MPzzlaU0aX6ysPLtTSdbVhlwQAANBjCJEHoDAvqtmXTlP/opiunFupzfWNYZcEAADQIwiRB2hI/0LdcVlcm+sb9fl756sp0Rp2SQAAAAcdIbIbHDOqXD899xi98tZWfeePi5mxDQAA+jwm1nSTs6aM1MqNdbr1uTd0+LBSfebEQ8IuCQAA4KDpdCTSzArN7BUzW2hmS8zshjRtTjKz+WaWMLNzU9a1mNmC4PZ4dxafba776OH66JFD9b0nlupvq6rDLgcAAOCgyeRwdqOkk919sqQpkmaY2Qkpbd6R9GlJ96fZfpe7TwluZx5QtVkuEjH94oIpGj+kVF+4b77erK4PuyQAAICDotMQ6Um701BecPOUNm+5+yJJOT+rpKQgpjtnxhWLRnTF3Ept39UcdkkAAADdLqOJNWYWNbMFkjZJmufuL3fhPQrNrNLM/mFmn9zHe8wK2lVWV/fuQ8GjBxbrN586Vu9s2alrHnhNLa1MtAEAAH1LRiHS3VvcfYqkUZKmm9mkLrzHGHePS7pY0i/N7AMdvMdsd4+7e7yioqILL5+dTjh0kG48a5L+urJaP35qWdjlAAAAdKsu/cSPu9dIel7SjC5ssy64fzPYdmpX3rM3u/j4MZr5wbG6429r9EjV2rDLAQAA6DaZzM6uMLPy4HGRpFMlLc/kxc1sgJkVBI8HSzpR0tL9L7f3+dYnjtQ/fWCQrv/D66p6e2vY5QAAAHSLTEYih0t6zswWSXpVyXMinzCzG83sTEkys+PMbK2k8yTdbmZLgm2PkFRpZgslPSfpx+6eUyEyLxrRbz51rIaXF+qz98zXuppdYZcEAABwwCwbr64Sj8e9srIy7DK61aqNdTr7N/+rsYOK9fBVH1RxPr/zDgAAspuZVQVzW/bCZQ97yPihpfr1RVO1dH2t/v3hRVwaEQAA9GqEyB70kYlD9PUZE/Xk6+t18zOrwy4HAABgv3FMtYfNOulQrdhQp188vVIThpbotKOHh10SAABAlzES2cPMTD8852hNHVOuax9aqCXrtoddEgAAQJcRIkNQmBfV7ZdMU1lRnmbNrdLm+sawSwIAAOgSQmRIhvQv1B2XxbW5vlGfu7dKTYmcv+w4AADoRQiRITp6VJl+dt5kvfrWNn37scXM2AYAAL0GE2tC9q+TR2jFhjrd8txqHT6sVP/2oUPCLgkAAKBTjERmgWs/OkEfO3Kovv/kUr2wsjrscgAAADpFiMwCkYjpFxdM0YShpbr6/vl6s7o+7JIAAAD2iRCZJfoVxHTHZXHFohFdMadS23c1h10SAABAhwiRWWT0wGL99lPH6p2tO/XFB15TooUZ2wAAIDsRIrPM8YcO0vc+OUkvrKzWj55aHnY5AAAAaTE7OwtdNH2MVmyo010vrtHhw0p1fnx02CUBAAC0w0hklvrWGUfoQ4cN1rceXayqt7eGXQ4AAEA7hMgsFYtGdMvFUzWivFCfvadK79XsCrskAACAPQiRWay8OF93zoyrsblVV86p1M6mRNglAQAASCJEZr3DhpTq5oumatmGWn314YVqbeXSiAAAIHyEyF7gIxOH6BunTdSfXt+gm59dFXY5AAAAzM7uLa788KFavqFOv3x6lQ4fWqrTjh4edkkAACCHMRLZS5iZfnj20Zo6plzXPrRQS9ZtD7skAACQwwiRvUhhXlS3XzpN5cV5unJOparrGsMuCQAA5KhOQ6SZFZrZK2a20MyWmNkNadqcZGbzzSxhZuemrJtpZquC28zuLD4XDSkt1B2XxbV1Z5M+d2+VGhMtYZcEAAByUCYjkY2STnb3yZKmSJphZiektHlH0qcl3d92oZkNlPRdScdLmi7pu2Y24ECLznWTRpbpZ+dNVuXb2/TtxxbLnRnbAACgZ3UaIj2pPniaF9w8pc1b7r5IUmvK5h+XNM/dt7r7NknzJM048LLxiWNG6IsnH6aHKtfq7pfeCrscAACQYzI6J9LMoma2QNImJUPhyxm+/khJ77Z5vjZYlu49ZplZpZlVVldXZ/jyue0rp07Qx48aqh88uVR/XUmfAQCAnpNRiHT3FnefImmUpOlmNinD17d0L9fBe8x297i7xysqKjJ8+dwWiZhuOn+KJgwt1dX3z9cb1fWdbwQAANANujQ7291rJD2vzA9Jr5U0us3zUZLWdeU9sW/9CmK647K48qIRXTmnUtt3NoddEgAAyAGZzM6uMLPy4HGRpFMlLc/w9f8i6WNmNiCYUPOxYBm60eiBxbrtkml6d9tOXf3AfCVaUk9NBQAA6F6ZjEQOl/ScmS2S9KqS50Q+YWY3mtmZkmRmx5nZWknnSbrdzJZIkrtvlfS9YLtXJd0YLEM3m37IQH3vrEn626rN+uGfMs34AAAA+6fTyx4Gs66npln+nTaPX1XyUHW67e+WdPcB1IgMXTh9jJZvqNPdL63RxGGlOv+40Z1vBAAAsB+4Yk0f860zjtCHxw/WNx97XZVvMegLAAAODkJkHxOLRnTLRcdqZHmRrrq3Su/V7Aq7JAAA0AcRIvugsuI83TnzODU2t+qKOZXa2ZQIuyQAANDHECL7qMOGlOjmi6dqxYZaXffQQrW2cmlEAADQfQiRfdhHDh+ib5x2hJ5avEG/emZV2OUAAIA+pNPZ2ejdrvjwIVqxsU6/emaVJgwt1RnHDA+7JAAA0AcwEtnHmZl+cPYkHTumXNc9vECL39sedkkAAKAPIETmgIJYVLddOk0DivM1a26lqusawy4JAAD0coTIHDGktFB3XBbX1p1NuureKjUmWsIuCQAA9GKEyBwyaWSZfn7eFFW9vU3fenSx3JmxDQAA9g8hMsecccxwXXPKeD1ctVZ3vbgm7HIAAEAvRYjMQV8+Zbw+ftRQ/fBPy/TXldVhlwMAAHohQmQOikRMN50/RROGlurq++frjer6sEsCAAC9DCEyR/UriOnOmXHlRyO6Yk6ltu9sDrskAADQixAic9ioAcW67dJpWrttp65+YL4SLa1hlwQAAHoJQmSOO27cQH3/k5P0t1Wb9YM/LQu7HAAA0Etw2UPoguPGaPmGOv2/l97SxGGluuC4MWGXBAAAshwjkZAkffP0I/Th8YP1rccW69W3toZdDgAAyHKESEiSYtGIbrnoWI0eUKyr7qnS2m07wy4JAABkMUIk9igrztMdM+NqamnVlXOrtKMxEXZJAAAgSxEi0c4HKkr064umasWGWl330EK1tnJpRAAAsDdCJPbyL4cP0fWnH6E/L9mgXz6zKuxyAABAFuo0RJpZoZm9YmYLzWyJmd2Qpk2BmT1oZqvN7GUzGxcsH2dmu8xsQXC7rfs/Ag6Gyz90iM6dNko3P7NKTy5aH3Y5AAAgy2TyEz+Nkk5293ozy5P0opk95e7/aNPmcknb3P0wM7tQ0k8kXRCse8Pdp3Rv2TjYzEw/OHuS1mzeoeseXqCxg4o1aWRZ2GUBAIAs0elIpCftvrhyXnBLPVHuLElzgsePSDrFzKzbqkQoCmJR3XbJNA0szteVcyu1qa4h7JIAAECWyOicSDOLmtkCSZskzXP3l1OajJT0riS5e0LSdkmDgnWHmNlrZvZXM/vwPt5jlplVmllldXV1lz8IDo6K0gLNviyump3NuuqeKjUmWsIuCQAAZIGMQqS7twSHpEdJmm5mk1KapBt1dEnrJY1x96mSrpV0v5n17+A9Zrt73N3jFRUVmX8CHHSTRpbp5+dP1vx3avTNRxfLnRnbAADkui7Nznb3GknPS5qRsmqtpNGSZGYxSWWStrp7o7tvCbatkvSGpAkHWDNCcPrRw/WlU8brkaq1uuvFNWGXAwAAQpbJ7OwKMysPHhdJOlXS8pRmj0uaGTw+V9Kz7u7BttFg20MljZf0ZncVj571pVPG67RJw/TDPy3Tcys2hV0OAAAIUSYjkcMlPWdmiyS9quQ5kU+Y2Y1mdmbQ5i5Jg8xstZKHrb8eLD9J0iIzW6jkhJur3J0LM/dSkYjp5+dP1uHD+uua+1/T6k31nW8EAAD6JMvG89vi8bhXVlaGXQY6sHbbTp11y0vqX5Snxz5/osqK88IuCQAAHARmVuXu8XTruGINumzUgGLdfuk0rd22U1+4f74SLa1hlwQAAHoYIRL7JT5uoH7wyaP14urN+v6Ty8IuBwAA9LBMrlgDpHX+caO1fEOd7n5pjSYOK9WF08eEXRIAAOghjETigFx/+kSdNKFC3/7jYr2yhjlTAADkCkIkDkgsGtGvL5qq0QOKddW9VVq7bWfYJQEAgB5AiMQBKyvK0x0z42puadUVcyq1ozERdkkAAOAgI0SiW3ygokS3XnysVm6s07UPLVBra/b9dBQAAOg+hEh0m5MmVOibZxypvyzZqF8+vTLscgAAwEHE7Gx0q387cZyWr6/Vzc+u1oRhpfrEMSPCLgkAABwEjESiW5mZvn/2JE0bO0BffXihFr+3PeySAADAQUCIRLcriEV12yXTNLA4X1fOrdSmuoawSwIAAN2MEImDoqK0QHfMjKtmZ7M+e0+VGppbwi4JAAB0I0IkDpqjRpTppvMn67V3avTNRxfLnRnbAAD0FYRIHFSnHT1cXz51vH4/f63u/NuasMsBAADdhBCJg+6ak8fr9KOH6UdPLdNzKzaFXQ4AAOgGhEgcdJGI6WfnTdbEYf11zf2vafWmurBLAgAAB4gQiR5RnB/THTPjKsiL6Io5larZ2RR2SQAA4AAQItFjRpYX6bZLpum9ml26+v7XlGhpDbskAACwnwiR6FHxcQP1g7OP1ourN+v7Ty4LuxwAALCfuOwhetz58dFasaFOd724RocPK9VF08eEXRIAAOgiRiIRim+cNlEnTajQtx9brJff3BJ2OQAAoIsIkQhFLBrRry+aqjGDivW5++br3a07wy4JAAB0Qach0swKzewVM1toZkvM7IY0bQrM7EEzW21mL5vZuDbrvhEsX2FmH+/e8tGblRXl6c7L4kq0tOrKuZXa0ZgIuyQAAJChTEYiGyWd7O6TJU2RNMPMTkhpc7mkbe5+mKRfSPqJJJnZkZIulHSUpBmSfmNm0e4qHr3foRUluuXiY7VyY52+8uACtbZyaUQAAHqDTkOkJ9UHT/OCW+o3/VmS5gSPH5F0iplZsPx37t7o7mskrZY0vVsqR59x0oQKfeuMI/U/SzfqF0+vDLscAACQgYzOiTSzqJktkLRJ0jx3fzmlyUhJ70qSuyckbZc0qO3ywNpgWbr3mGVmlWZWWV1d3bVPgV7vMyeO0wXx0fr1s6v13wvXhV0OAADoREYh0t1b3H2KpFGSppvZpJQmlm6zfSxP9x6z3T3u7vGKiopMykIfYma68ZNHKT52gL768EK9vnZ72CUBAIB96NLsbHevkfS8kuc3trVW0mhJMrOYpDJJW9suD4ySxDAT0iqIRXXbpdM0uKRAV86t1KbahrBLAgAAHchkdnaFmZUHj4sknSppeUqzxyXNDB6fK+lZd/dg+YXB7O1DJI2X9Ep3FY++Z3BJgWZfNk3bdzVr1j1VamhuCbskAACQRiYjkcMlPWdmiyS9quQ5kU+Y2Y1mdmbQ5i5Jg8xstaRrJX1dktx9iaSHJC2V9GdJX3B3UgH26agRZfrFBZO14N0aXf+H15X8/wgAAMgmlo1f0PF43CsrK8MuAyH71dOr9IunV+r60ydq1kkfCLscAAByjplVuXs83TquWIOsdc0ph+mMo4frR08t13PLN4VdDgAAaIMQiaxlZvrZeZN15PD+uuaB17R6U13YJQEAgAAhElmtKD+qOy6LqyAvqsvnVKpmZ1PYJQEAABEi0QuMKC/S7ZdO0/qaBn3h/vlqbmkNuyQAAHIeIRK9wrSxA/SDsyfppdVb9P0nloZdDgAAOS8WdgFAps6Lj9aKDXW688U1OnxYf118/JiwSwIAIGcxEole5RunH6F/nlCh7/xxsf7x5pawywEAIGcRItGrRCOmmy+aqjGDivW5e6v07tadYZcEAEBOIkSi1ykrytNdM49TS6vrijmVqm9MhF0SAAA5hxCJXumQwf1066eO1erqen3lwQVqbc2+Ky8BANCXESLRa314fIW+dcYRmrd0o26atzLscgAAyCnMzkav9ul/GqcVG+p0y3OrNWFYqc6cPCLskgAAyAmMRKJXMzPdeNYkHTdugP794YVatLYm7JIAAMgJhEj0evmxiH57yTQNLinQrLlV2lTbEHZJAAD0eYRI9AmDSwp0x2Vx1TY068p7qtTQ3BJ2SQAA9GmESPQZR47or5vOn6KF79boG394Xe7M2AYA4GAhRKJPmTFpmK796AQ9+tp7uv2FN8MuBwCAPosQiT7niycfpjOOGa6f/Hm5nl2+MexyAADokwiR6HPMTD87d7KOGtFf1zywQKs21oVdEgAAfQ4hEn1SUX5Usy+NqzAvqivmVmrbjqawSwIAoE8hRKLPGlFepNmXTdP6mgZ94f75am5pDbskAAD6DEIk+rRjxwzQD885Wv/7xhZ974mlYZcDAECf0WmINLPRZvacmS0zsyVm9qU0bQaY2aNmtsjMXjGzSW3WvWVmr5vZAjOr7O4PAHTm3GmjdOWHD9Hcv7+t+15+O+xyAADoEzK5dnZC0nXuPt/MSiVVmdk8d287rHO9pAXufraZTZR0q6RT2qz/iLtv7r6yga75+mlHaNWmen33j0t06OASffADg8IuCQCAXq3TkUh3X+/u84PHdZKWSRqZ0uxISc8EbZZLGmdmQ7u5VmC/RSOmmy+aqrGDivX5+6r0zpadYZcEAECv1qVzIs1snKSpkl5OWbVQ0jlBm+mSxkoaFaxzSf9jZlVmNmsfrz3LzCrNrLK6urorZQEZ6V+YpztnHqdWl66cW6n6xkTYJQEA0GtlHCLNrETS7yV92d1rU1b/WNIAM1sg6YuSXlPyMLgknejux0o6TdIXzOykdK/v7rPdPe7u8YqKiq5+DiAjhwzup1svPlarq+v1lQcXqLWVSyMCALA/MgqRZpanZIC8z93/kLre3Wvd/TPuPkXSZZIqJK0J1q0L7jdJelTS9G6qHdgvHxo/WN8+4wjNW7pRP5+3IuxyAADolTKZnW2S7pK0zN1v6qBNuZnlB0+vkPSCu9eaWb9gMo7MrJ+kj0la3D2lA/tv5j+N00XTR+vW597QHxe8F3Y5AAD0OpnMzj5R0qWSXg8OV0vJ2dhjJMndb5N0hKS5ZtYiaamky4N2QyU9msyhikm6393/3H3lA/vHzHTDmZP0RvUOfe2RRRo3qJ8mjy4PuywAAHoNc8++c8Li8bhXVvKTkjj4ttQ36sxbXlKitVWPX/0hDe1fGHZJAABkDTOrcvd4unVcsQY5bVBJge6cGVddQ0Kz7qlSQ3NL2CUBANArECKR844Y3l83nT9FC9+t0dd/v0jZODoPAEC2IUQCkmZMGqbrPjpBjy1Yp9v++mbY5QAAkPUIkUDg6pMP0yeOGa6f/mW5nlm2MexyAADIaoRIIGBm+s9zJ2vSiDJ96XcLtHJjXdglAQCQtQiRQBtF+VHNvmyaivKjumJOpbbtaAq7JAAAshIhEkgxvKxIt186TRtqG/T5++aruaU17JIAAMg6hEggjWPHDNCPzzlaf39zi27876VhlwMAQNbJ5Io1QE4659hRWrGhTre/8KYOH1aqS04YG3ZJAABkDUYigX342oyJ+sjhFfqPx5fo729sCbscAACyBiES2IdoxPSri6Zq3OB++tx9VVqybrsSnCMJAADXzgYy8dbmHTrr1pe0fVezIiYNKS3UiPJCDS8v0oiyQg0vK0o+LyvS8PJCDe5XoEjEwi4bAIADsq9rZ3NOJJCBcYP76fGrT9RLq7do/fZdWlfToPXbd2npulo9vXSjGhPtRyfzoxENLSvQiLIijSgv0vCyvQNnWVGezAiaAIDeiRAJZGjsoH4aO6jfXsvdXdt2NmtdzS6tq9ml9dsbtG77Lq0PguYra7ZqY22DEq3tR/2L8qIaXl6okbtDZpvRzN33/Qr4JwoAyE58QwEHyMw0sF++BvbL16SRZWnbtLS6Ntc36r2a98Pl7tHMddsbtGJDtarrG5V6dkn/wphGlL8/mjkiJXAOKytUQSzaA58SAID2CJFAD4hGTEP7F2po/0JpTPo2TYlWbaxtSDuaua6mQa+9s03bdjbvtd3gkvy9wmXb+yGlBYpFmUMHAOhehEggS+THIho9sFijBxZ32GZXU8ueUNkuZG5v0JvVO/TS6i2qb0y02yYaMQ0pLehwNHN4WZEGl+RzfiYAoEsIkUAvUpQf1aEVJTq0oqTDNrUNyfMz17cJmrvvF7+3Xf+zdKOa0kwEGlaWnHE+Iphh3m5Us6xI/YtiBE0AwB6ESKCP6V+Yp/7D8jRxWP+0691dW3c0tRnN3H34vEHra3bp5TVbtaG2QS0pE4GK86N7RjJ3B83UwFmcz58UAMgV/MUHcoyZaVBJgQaVFOjoUR1PBKquCyYCpYxmrt++S8s31Km6rnGv7cqK8oKQWZh2NHNYWaHyY5yfCQB9ASESwF6iEdOwsuTsb2lA2ja7JwLtDpq7Z5snA2eDqt7Zppq0E4EKNLLND7OnjmYOKS1UlB9qB4CsR4gEsF8ymQi0symREi7fv19dXa+/rarWjqaWdttEI6ahuycC7fmB9t0/1p4MnIP6MREIAMLWaYg0s9GS5koaJqlV0mx3/1VKmwGS7pb0AUkNkv7N3RcH62ZI+pWkqKQ73f3H3foJAGSt4vyYDhtSosOGpJ8I5O6qbUgEP2uUOpq5S4vW1ugvixvUlHK98vxYJHl+ZspoZttRzf6FTAQCgIMpk5HIhKTr3H2+mZVKqjKzee6+tE2b6yUtcPezzWyipFslnWJm0eDxRyWtlfSqmT2esi2AHGVmKivKU1lRno4Y3vFEoC07moIrAgUhc/v7v6f5jze2aGNd414TgfrlR1NGM/cOnEX5/FA7AOyvTkOku6+XtD54XGdmyySNlNQ2CB4p6UdBm+VmNs7Mhko6VNJqd39Tkszsd5LOStkWADpkZhpcUqDBJQU6ZlT6NomWVlXXN7YLmm0D59J1tdpcv/dEoPLivOD65ikhM5iFPrQ/E4EAoCNdOifSzMZJmirp5ZRVCyWdI+lFM5suaaykUUqGzXfbtFsr6fgOXnuWpFmSNGZMB5f0AIA0YtFIMgSWFWna2PRtGhMt2rC9Ie1o5tptu/TqW9u0fVf7iUBmyYlAI9qMZqYGzorSAiYCAchJGYdIMyuR9HtJX3b32pTVP5b0KzNbIOl1Sa8peRg83V9WT7NM7j5b0mxJisfjadsAwP4qiEU1dlA/jR3Ur8M2OxoT7a9r3iZwrtxYp7+urNbOlIlAseCSlnuuBtBZCAEAAAo3SURBVBSEy2FlhepfmKfSwphKCmLJ+8IY1zoH0GdkFCLNLE/JAHmfu/8hdX0QKj8TtDVJa4JbsaTRbZqOkrTuAGsGgIOiX0FMhw0p1WFDStOud3fV7kq8/7NGwQ+07x7VXPBujf6cZiJQW/nRiEraBss298nlyeC5Z1mwvH9hXps2MRXEIkwcAhCqTGZnm6S7JC1z95s6aFMuaae7N0m6QtIL7l5rZq9KGm9mh0h6T9KFki7utuoBoAeZmcqK81RWnKcjR6SfCNTampwItLG2QbUNzapvSKi+MaG6dvfJ5XUNCdU1Jn8Gqb5x9/pmNbd0fjAmL2pBAH0/XJbuvm8TRtsG0dLCmEoL8tqFWMIogP2VyUjkiZIulfR6cLhaSs7GHiNJ7n6bpCMkzTWzFiUnzVwerEuY2dWS/qLkT/zc7e5LuvcjAED2iERMFaUFqigt2O/XaGhuSYbKNsGzrqG5TdBM7Fm/e3ldQ0IbahtUX/1++66E0T2joO2CaJtwujuwtgmrbUdJCaNA7jH37Dv9MB6Pe2VlZdhlAECv1phoSQmiQfjcPRK6O5CmjJK2C6mNCTUlOj48v1ssYu8Hy4Lg8HvaIBpTSTB6mnq+aGlBngrzCKNANjGzKnePp1vHFWsAoI8qiEVVUBLVoJL9HxWVkmF0R2OL6hraB8zdh9/r2jx/P5w2a1Ndg96sfj+gNmYQRqMR2xNE250bGgTP/u3OH005dN9mlLQoL0oYBQ4yQiQAYJ8KYlEVxKIa2C//gF6nKdHaJmi2P1/0/SDa/nzR+oaENtc36a0tO/ccpt+fMNo+eO59vmj/IIymTnoqzieMAh0hRAIAekR+LKKBsfxuCaM7GjM7X7TtKOnWHU16Owij9Y3NamjuPIxGTHtPYEqdVR+Ez9KU80WTI6l5hFH0WYRIAECvkh+LKD+WrwEHGEabW5JhNPV80XYz6dOcL7p1R5Pe2bJzT0Dd1dzS6XtFLPkTUu9PXGo/q74oP6rCvKgKY1EV5kVUEIskn+dF9zwuyIuoIFifuq4wFlEsytWV0LMIkQCAnJQXjai8OF/lxQcWRhMtre1HQYNwWbt7hHSvn3lKLq/Z2aR3tyVHRnc1tagx0ZLRjPqORCOmwt2Bc0/wTAmlsWQY3RNWgwBakBpKUwJr2+13rysIXpcR1txFiAQA4ADEuimMSslA2phoVUNzy577huZWNSaS9w2JFjXued6+TUfbNAbbbN3RtPfrBdsciI6CZ2Gs/ehp2lCa8rwgNeR2MPLKpUazAyESAIAsEYsmD0v3K+i5r2d3V2OitU04TYbVDoNsm+WNzS1qSLQm79uE3N3b1zcmJ0Yl17d5vUSrWlr3f9Q1L2rtwmkmwbPd6QDttuk45LbdJj/KqGsqQiQAADnMzPYELimvx9430dKqhr1GXduPnqauSz7eO6w2poTc+sZEEFbff52GRGtGv3naETPtfTpAm9MC2p7HmjxF4P2QmjpaW5DuvNYOQm4ki0ddCZEAAKDHxaIRlUQjKunBUdfWVldTy75HVxvajq4G93sH2b23q21IqLquMc3pCC06gEFX5Ucje02q+uUFUzRpZFn3dcx+IkQCAICcEImYCiO7R117hrurucXTnw7QbkS1fahNF3Ibg9HVnjzdYV+yowoAAIA+yMyUHzPlxyIqLQy7mu7Fj0oBAACgywiRAAAA6DJCJAAAALqMEAkAAIAuI0QCAACgywiRAAAA6DJCJAAAALqMEAkAAIAuM/cDuBbPQWJm1ZLe7qG3Gyxpcw+9V29Cv6RHv6RHv+yNPkmPfkmPfkmPftlbT/fJWHevSLciK0NkTzKzSnePh11HtqFf0qNf0qNf9kafpEe/pEe/pEe/7C2b+oTD2QAAAOgyQiQAAAC6jBApzQ67gCxFv6RHv6RHv+yNPkmPfkmPfkmPftlb1vRJzp8TCQAAgK5jJBIAAABdRogEAABAl+VMiDSzGWa2wsxWm9nX06wvMLMHg/Uvm9m4nq+y52XQL582s2ozWxDcrgijzp5kZneb2SYzW9zBejOzm4M+W2Rmx/Z0jWHIoF/+xcy2t9lXvtPTNfY0MxttZs+Z2TIzW2JmX0rTJuf2lwz7JRf3l0Ize8XMFgb9ckOaNjn3XZRhv+Tcd5EkmVnUzF4zsyfSrAt9X4n19BuGwcyikm6V9FFJayW9amaPu/vSNs0ul7TN3Q8zswsl/UTSBT1fbc/JsF8k6UF3v7rHCwzPf0m6RdLcDtafJml8cDte0m+D+77uv7TvfpGkv7n7J3qmnKyQkHSdu883s1JJVWY2L+XfUC7uL5n0i5R7+0ujpJPdvd7M8iS9aGZPufs/2rTJue8iZdYvUu59F0nSlyQtk9Q/zbrQ95VcGYmcLmm1u7/p7k2SfifprJQ2Z0maEzx+RNIpZmY9WGMYMumXnOPuL0jauo8mZ0ma60n/kFRuZsN7prrwZNAvOcfd17v7/OBxnZJ/7EemNMu5/SXDfsk5wT5QHzzNC26ps1tz7rsow37JOWY2StIZku7soEno+0quhMiRkt5t83yt9v6DtqeNuyckbZc0qEeqC08m/SJJ/yc4DPeImY3umdKyWqb9los+GBySesrMjgq7mJ4UHEqaKunllFU5vb/so1+kHNxfgsOTCyRtkjTP3TvcX3LouyiTfpFy77vol5K+Jqm1g/Wh7yu5EiLTJfPU/+Vk0qavyeQz/7ekce5+jKSn9f7/enJZLu4rmZiv5DVWJ0v6taTHQq6nx5hZiaTfS/qyu9emrk6zSU7sL530S07uL+7e4u5TJI2SNN3MJqU0ycn9JYN+yanvIjP7hKRN7l61r2ZplvXovpIrIXKtpLb/axklaV1HbcwsJqlMff/QXaf94u5b3L0xeHqHpGk9VFs2y2R/yjnuXrv7kJS7/0lSnpkNDrmsgy44h+v3ku5z9z+kaZKT+0tn/ZKr+8tu7l4j6XlJM1JW5eJ30R4d9UsOfhedKOlMM3tLyVPNTjaze1PahL6v5EqIfFXSeDM7xMzyJV0o6fGUNo9Lmhk8PlfSs973f4m9035JOXfrTCXPbcp1j0u6LJh1e4Kk7e6+PuyiwmZmw3afj2Nm05X8+7Il3KoOruDz3iVpmbvf1EGznNtfMumXHN1fKsysPHhcJOlUSctTmuXcd1Em/ZJr30Xu/g13H+Xu45T8bn7W3S9JaRb6vpITs7PdPWFmV0v6i6SopLvdfYmZ3Sip0t0fV/IP3j1mtlrJJH9heBX3jAz75RozO1PJ2ZZbJX06tIJ7iJk9IOlfJA02s7WSvqvkid5y99sk/UnS6ZJWS9op6TPhVNqzMuiXcyV9zswSknZJurCvf/kpOVpwqaTXg/O5JOl6SWOknN5fMumXXNxfhkuaE/wyRkTSQ+7+RK5/Fymzfsm576J0sm1f4bKHAAAA6LJcOZwNAACAbkSIBAAAQJcRIgEAANBlhEgAAAB0GSESAAAAXUaIBAAAQJcRIgEAANBl/x86zH+xxnOoMwAAAABJRU5ErkJggg==\n",
      "text/html": [
       "\n",
       "\n",
       "<style>\n",
       "\n",
       "</style>\n",
       "\n",
       "<div id=\"fig_el1336417038684311047668622711\"></div>\n",
       "<script>\n",
       "function mpld3_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(mpld3) !== \"undefined\" && mpld3._mpld3IsLoaded){\n",
       "   // already loaded: just create the figure\n",
       "   !function(mpld3){\n",
       "       \n",
       "       mpld3.draw_figure(\"fig_el1336417038684311047668622711\", {\"width\": 792.0, \"height\": 288.0, \"axes\": [{\"bbox\": [0.125, 0.125, 0.775, 0.755], \"xlim\": [-0.2, 4.2], \"ylim\": [2.860875715958398, 3.2107478662179774], \"xdomain\": [-0.2, 4.2], \"ydomain\": [2.860875715958398, 3.2107478662179774], \"xscale\": \"linear\", \"yscale\": \"linear\", \"axes\": [{\"position\": \"bottom\", \"nticks\": 11, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}, {\"position\": \"left\", \"nticks\": 9, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}], \"axesbg\": \"#FFFFFF\", \"axesbgalpha\": null, \"zoomable\": true, \"id\": \"el133641703868430992\", \"lines\": [{\"data\": \"data01\", \"xindex\": 0, \"yindex\": 1, \"coordinates\": \"data\", \"id\": \"el133641703866795064\", \"color\": \"#1F77B4\", \"linewidth\": 1.5, \"dasharray\": \"none\", \"alpha\": 1, \"zorder\": 2, \"drawstyle\": \"default\"}], \"paths\": [], \"markers\": [], \"texts\": [], \"collections\": [], \"images\": [], \"sharex\": [], \"sharey\": []}], \"data\": {\"data01\": [[0.0, 3.194844586660724], [1.0, 2.922369933431525], [2.0, 2.896844863237074], [3.0, 2.8844067835740743], [4.0, 2.8767789955156515]]}, \"id\": \"el133641703868431104\", \"plugins\": [{\"type\": \"reset\"}, {\"type\": \"zoom\", \"button\": true, \"enabled\": false}, {\"type\": \"boxzoom\", \"button\": true, \"enabled\": false}]});\n",
       "   }(mpld3);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/mpld3\n",
       "   require.config({paths: {d3: \"https://mpld3.github.io/js/d3.v3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      mpld3_load_lib(\"https://mpld3.github.io/js/mpld3.v0.3.1.dev1.js\", function(){\n",
       "         \n",
       "         mpld3.draw_figure(\"fig_el1336417038684311047668622711\", {\"width\": 792.0, \"height\": 288.0, \"axes\": [{\"bbox\": [0.125, 0.125, 0.775, 0.755], \"xlim\": [-0.2, 4.2], \"ylim\": [2.860875715958398, 3.2107478662179774], \"xdomain\": [-0.2, 4.2], \"ydomain\": [2.860875715958398, 3.2107478662179774], \"xscale\": \"linear\", \"yscale\": \"linear\", \"axes\": [{\"position\": \"bottom\", \"nticks\": 11, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}, {\"position\": \"left\", \"nticks\": 9, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}], \"axesbg\": \"#FFFFFF\", \"axesbgalpha\": null, \"zoomable\": true, \"id\": \"el133641703868430992\", \"lines\": [{\"data\": \"data01\", \"xindex\": 0, \"yindex\": 1, \"coordinates\": \"data\", \"id\": \"el133641703866795064\", \"color\": \"#1F77B4\", \"linewidth\": 1.5, \"dasharray\": \"none\", \"alpha\": 1, \"zorder\": 2, \"drawstyle\": \"default\"}], \"paths\": [], \"markers\": [], \"texts\": [], \"collections\": [], \"images\": [], \"sharex\": [], \"sharey\": []}], \"data\": {\"data01\": [[0.0, 3.194844586660724], [1.0, 2.922369933431525], [2.0, 2.896844863237074], [3.0, 2.8844067835740743], [4.0, 2.8767789955156515]]}, \"id\": \"el133641703868431104\", \"plugins\": [{\"type\": \"reset\"}, {\"type\": \"zoom\", \"button\": true, \"enabled\": false}, {\"type\": \"boxzoom\", \"button\": true, \"enabled\": false}]});\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & mpld3\n",
       "    mpld3_load_lib(\"https://mpld3.github.io/js/d3.v3.min.js\", function(){\n",
       "         mpld3_load_lib(\"https://mpld3.github.io/js/mpld3.v0.3.1.dev1.js\", function(){\n",
       "                 \n",
       "                 mpld3.draw_figure(\"fig_el1336417038684311047668622711\", {\"width\": 792.0, \"height\": 288.0, \"axes\": [{\"bbox\": [0.125, 0.125, 0.775, 0.755], \"xlim\": [-0.2, 4.2], \"ylim\": [2.860875715958398, 3.2107478662179774], \"xdomain\": [-0.2, 4.2], \"ydomain\": [2.860875715958398, 3.2107478662179774], \"xscale\": \"linear\", \"yscale\": \"linear\", \"axes\": [{\"position\": \"bottom\", \"nticks\": 11, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}, {\"position\": \"left\", \"nticks\": 9, \"tickvalues\": null, \"tickformat\": null, \"scale\": \"linear\", \"fontsize\": 10.0, \"grid\": {\"gridOn\": false}, \"visible\": true}], \"axesbg\": \"#FFFFFF\", \"axesbgalpha\": null, \"zoomable\": true, \"id\": \"el133641703868430992\", \"lines\": [{\"data\": \"data01\", \"xindex\": 0, \"yindex\": 1, \"coordinates\": \"data\", \"id\": \"el133641703866795064\", \"color\": \"#1F77B4\", \"linewidth\": 1.5, \"dasharray\": \"none\", \"alpha\": 1, \"zorder\": 2, \"drawstyle\": \"default\"}], \"paths\": [], \"markers\": [], \"texts\": [], \"collections\": [], \"images\": [], \"sharex\": [], \"sharey\": []}], \"data\": {\"data01\": [[0.0, 3.194844586660724], [1.0, 2.922369933431525], [2.0, 2.896844863237074], [3.0, 2.8844067835740743], [4.0, 2.8767789955156515]]}, \"id\": \"el133641703868431104\", \"plugins\": [{\"type\": \"reset\"}, {\"type\": \"zoom\", \"button\": true, \"enabled\": false}, {\"type\": \"boxzoom\", \"button\": true, \"enabled\": false}]});\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<Figure size 792x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e.weight torch.Size([2003, 10])\n",
      "Winv.weight torch.Size([2003, 10])\n",
      "Winv.bias torch.Size([2003])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape) # param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2003, 10]),\n",
       " tensor([[-0.6900, -1.0527, -0.6088,  ..., -0.0270, -0.5310, -0.6188],\n",
       "         [-0.3624,  0.5101,  0.3138,  ..., -1.2582, -0.5701, -1.4912],\n",
       "         [ 1.7894,  1.2133, -0.6401,  ...,  0.0681, -0.5708, -1.5545],\n",
       "         ...,\n",
       "         [ 1.0353,  0.5522, -1.1476,  ..., -0.2062, -0.9804,  0.4113],\n",
       "         [ 0.5618,  0.6092,  0.3533,  ..., -1.2363, -1.4847,  1.7156],\n",
       "         [ 1.8045,  0.5759,  1.1551,  ...,  0.8487, -0.3051,  0.6697]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embedding = model.e.weight.data\n",
    "Embedding.shape, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_analogy(pos_neg_1=('king','man'),pos_neg_2=('queen','woman'), n_closest = 4):\n",
    "    king_w,    man_w = pos_neg_1\n",
    "    queen_w, woman_w = pos_neg_2\n",
    "    \n",
    "    for w in (king_w,man_w,woman_w):\n",
    "        if w not in wiki_crawler.word2idx:\n",
    "            raise Exception(f'sorry, word \"{w}\" not in dictionary.')\n",
    "    \n",
    "    print(f'Expected: {king_w} - {man_w} = {queen_w} - {woman_w}')\n",
    "    \n",
    "    king   = wiki_crawler.word2idx[king_w]\n",
    "    man    = wiki_crawler.word2idx[man_w]\n",
    "    woman  = wiki_crawler.word2idx[woman_w]\n",
    "    \n",
    "    vec = (Embedding[king] - Embedding[man] + Embedding[woman]).view(1,-1) # Embedding[queen]\n",
    "    distances = pairwise_distances(vec.reshape(1, -1), Embedding, metric='cosine').reshape(V)\n",
    "    \n",
    "    idx = distances.argsort()[:n_closest+3] \n",
    "    idx = [x for x in idx if x not in set([man,king,woman])]\n",
    "    queen_estimated = wiki_crawler.idx2word[idx[0]]\n",
    "    \n",
    "    print(f'Got:      {king_w} - {man_w} = {queen_estimated} - {woman_w}')\n",
    "    \n",
    "    print(f'Closest {len(idx)} words:')\n",
    "    for i in idx:\n",
    "        print(f'{wiki_crawler.idx2word[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: rei - homem = rainha - mulher\n",
      "Got:      rei - homem = dias - mulher\n",
      "Closest 7 words:\n",
      "dias\n",
      "formar\n",
      "balcãs\n",
      "dois\n",
      "eventos\n",
      "contemporânea\n",
      "igreja\n"
     ]
    }
   ],
   "source": [
    "word_analogy(pos_neg_1=('rei','homem'),pos_neg_2=('rainha','mulher'), n_closest = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: rei - príncipe = rainha - princesa\n",
      "Got:      rei - príncipe = josé - princesa\n",
      "Closest 7 words:\n",
      "josé\n",
      "romanos\n",
      "subjetiva\n",
      "anexas\n",
      "considerada\n",
      "final\n",
      "pedra\n"
     ]
    }
   ],
   "source": [
    "word_analogy(pos_neg_1=('rei','príncipe'),pos_neg_2=('rainha','princesa'), n_closest = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: homem - mulher = ele - ela\n",
      "Got:      homem - mulher = terra - ela\n",
      "Closest 7 words:\n",
      "terra\n",
      "nome\n",
      "joão\n",
      "governar\n",
      "nomeado\n",
      "islão\n",
      "facto\n"
     ]
    }
   ],
   "source": [
    "word_analogy(pos_neg_1=('homem','mulher'),pos_neg_2=('ele','ela'), n_closest = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: homem - mulher = marido - esposa\n",
      "Got:      homem - mulher = milénio - esposa\n",
      "Closest 7 words:\n",
      "milénio\n",
      "definida\n",
      "governar\n",
      "quase\n",
      "nome\n",
      "lagos\n",
      "cresceu\n"
     ]
    }
   ],
   "source": [
    "word_analogy(pos_neg_1=('homem','mulher'),pos_neg_2=('marido','esposa'), n_closest = 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_negative_sampling_distribution(coded_sentences, V):\n",
    "    # Pn(w) = prob of word occuring\n",
    "    # we would like to sample the negative samples such that \n",
    "    # words that occur more often should be sampled more often\n",
    "    \n",
    "    freq  = np.zeros(V)                 # vector with V positions\n",
    "    for c in coded_sentences:\n",
    "        for w in c:\n",
    "            freq[w] += 1          # it is assumed that each word is actually its OHE index\n",
    "\n",
    "    f_neg = freq**0.75     # smoothing\n",
    "    pmf_neg = f_neg / f_neg.sum() # normalized pmf\n",
    "    \n",
    "    assert(np.all(pmf_neg > 0)) # check that only positive probabilities were drawn\n",
    "    \n",
    "    return pmf_neg\n",
    "\n",
    "# distribution for drawing negative samples\n",
    "pmf_neg = get_negative_sampling_distribution(wiki_crawler.coded_sentences, V) \n",
    "\n",
    "# for subsampling each sentence\n",
    "threshold = 1e-5 # 1 em 100.000\n",
    "p_drop = 1 - np.sqrt(threshold / pmf_neg)  # prob. de ignorar uma palavra :: aumenta conforme a frequência dessa palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
